---
name: doc2prod
description: FULLY IMPLEMENT complete projects from requirements to production. This skill executes the ENTIRE software development lifecycle - from discovery to deployment. It does NOT just plan, it IMPLEMENTS completely with phased execution, testing, and validation.
---

# DOC2PROD - Documentation to Production

**Part of ASG AI S2PROD by [AIShift](https://aishift.dev/)**

**Transform project requirements into fully functional production-ready applications through intelligent, phased implementation**

---

## üí° THE MOOT POINT (MANDATORY PHILOSOPHY)

**THE MAIN JOB OF THIS SKILL IS COMPLETE PROJECT DELIVERY.**

1.  **NEVER ASSUME**: Always perform thorough discovery before implementation
2.  **PHASED EXECUTION**: Break complex projects into manageable, testable phases
3.  **CONTINUOUS VALIDATION**: Test after every phase, fix gaps before proceeding
4.  **USER APPROVAL GATES**: Never skip phases without explicit user confirmation
5.  **DOCUMENTATION FIRST**: Document decisions, architecture, and implementation details
6.  **PRODUCTION READY**: Every deliverable must be deployment-ready, not just MVP

---

## Behavior

When activated, this skill will:
7. ‚úÖ Implement Phase 0: Foundation (auto + test)
8. ‚úÖ Implement Phase 1: Core Features (auto + test)
9. ‚úÖ Implement Phase 2+: Additional Features (auto + test)
10. ‚úÖ Generate comprehensive test suite (auto)
11. ‚úÖ Create manual testing guide (auto)
12. ‚úÖ Validate production readiness (auto)
13. ‚úÖ Report completion with deployment guide

**DO NOT ask "what would you like to do next?" after each phase - EXECUTE AUTOMATICALLY with user approval gates**

---

## Prerequisites (CHECK SILENTLY, DON'T ASK)

Check these silently and proceed:
- ‚úÖ Working directory exists and is writable
- ‚úÖ Node.js/Python/etc. installed (based on tech stack)
- ‚úÖ Package manager available (npm/yarn/pip/etc.)
- ‚úÖ Git initialized or can be initialized
- ‚úÖ Database server available or can be containerized

---

## ‚ö†Ô∏è CRITICAL RULES - MUST FOLLOW

### Rule 1: DISCOVERY PROOF (MANDATORY)

**BEFORE ANY IMPLEMENTATION, YOU MUST:**

```bash
# Map workspace structure
echo "üîç Mapping Workspace Topology..."
pwd
ls -la
find . -maxdepth 2 -not -path '*/.*' -type d
find . -maxdepth 1 -not -path '*/.*' -type f

# Check for existing projects
ls -la package.json 2>/dev/null || echo "No package.json found"
ls -la requirements.txt 2>/dev/null || echo "No requirements.txt found"
ls -la Gemfile 2>/dev/null || echo "No Gemfile found"
```

**Report to user:**
"Discovery Proof: I have mapped the workspace at `[path]`. Status: `[empty/existing project]`. I will create the new project in `[target_folder]`."

---

### Rule 2: AI-DRIVEN REQUIREMENTS ANALYSIS IS MANDATORY

**‚ö†Ô∏è NEW APPROACH - Ask ONE question, provide COMPLETE recommendations:**

1. **Single Question**: "Please describe your project in 2-3 sentences"
2. **AI Analysis**: Automatically detect project type, scale, features, and requirements
3. **Smart Recommendations**: Present complete architecture with justifications
4. **User Choice**: Approve, customize, or ask questions

**‚úÖ ALWAYS DO THIS:**
- ‚úÖ Ask for brief project description (2-3 sentences)
- ‚úÖ Analyze description to detect project type and scale
- ‚úÖ Automatically recommend complete tech stack with justifications
- ‚úÖ Present comprehensive architecture plan
- ‚úÖ Allow easy customization ("use MongoDB instead")
- ‚úÖ Use smart defaults from configuration matrix
- ‚úÖ Detect features from keywords automatically
- ‚úÖ Assign features to phases automatically

**‚ùå ABSOLUTELY FORBIDDEN:**
- ‚ùå Ask 8-9 separate questions (old approach)
- ‚ùå Ask about tech stack preferences without providing recommendations first
- ‚ùå Proceed without presenting a complete architecture recommendation
- ‚ùå Ignore user's customization requests
- ‚ùå Ask questions that can be inferred from project description
- ‚ùå Present recommendations without justifications

**Example Flow:**
```
User: "I need a SaaS platform for invoice management with team collaboration"

AI: [Analyzes internally]
- Project Type: SaaS
- Scale: Medium (business users)
- Features: Invoice CRUD, team management, RBAC, possibly payments

AI: [Presents complete recommendation]
"Based on your description, I recommend:
- Backend: Node.js + Express + TypeScript (real-time, scalable)
- Database: PostgreSQL (ACID compliance for financial data)
- Frontend: React + Tailwind CSS (modern SaaS UI)
- Auth: JWT with RBAC (team permissions)
- Features: Invoice management, team collaboration, payment integration

Approve to start, or customize any aspect."
```

---

### Rule 3: PHASED IMPLEMENTATION IS MANDATORY

**Every project MUST be broken into phases:**

- **P0**: Foundation (auth, database, core infrastructure)
- **P1**: Primary features (main business logic)
- **P2**: Secondary features (nice-to-have functionality)
- **P3**: Advanced features (optimizations, analytics)
- **P4**: Testing, documentation, deployment

**After EACH phase:**
1. ‚úÖ Implement all deliverables
2. ‚úÖ Run automated tests
3. ‚úÖ Perform gap analysis
4. ‚úÖ Fix all gaps
5. ‚úÖ Show summary to user
6. ‚úÖ Wait for approval before next phase

**‚ùå ABSOLUTELY FORBIDDEN:**
- ‚ùå Skip to next phase without completing current phase
- ‚ùå Ignore test failures
- ‚ùå Proceed without user approval
- ‚ùå Implement multiple phases simultaneously

---

### Rule 4: TESTING IS NON-NEGOTIABLE

**After EVERY phase, you MUST:**

```bash
# Run tests
npm test || pytest || cargo test

# Check for errors
echo "Checking for compilation errors..."
npm run build || tsc --noEmit || python -m py_compile src/**/*.py

# Test server startup
echo "Testing server startup..."
timeout 10s npm start || echo "Server start test complete"

# Verify endpoints (if applicable)
curl http://localhost:4000/health || echo "Health check endpoint test"
```

**If tests fail:**
1. ‚úÖ Analyze failure
2. ‚úÖ Fix the issue
3. ‚úÖ Re-run tests
4. ‚úÖ Repeat until all tests pass

**‚ùå NEVER proceed with failing tests**

---

## üõ†Ô∏è CRITICAL IMPLEMENTATION GOTCHAS (READ THIS)

### 1. Python + SQLAlchemy JSON Serialization
**Issue:** UUIDs or Datetime objects in a dictionary passed to a `JSON` or `JSONB` column will cause a `TypeError: Object is not JSON serializable`.
**Fix:** Always recursively convert UUIDs/Datetimes to strings before saving to a JSON field.

### 2. Python 3.12+ Bcrypt Compatibility
**Issue:** Newer versions of `bcrypt` have issues with Python 3.12+ leading to `ValueError` or compilation errors.
**Fix:** Pin `bcrypt==4.0.1` in `requirements.txt`.

### 3. FastAPI Query Parameters (UUID)
**Issue:** If a frontend sends an empty string `?id=` for a parameter typed as `UUID`, FastAPI returns a `422 Unprocessable Content`. 
**Fix:** 
- **Frontend**: Clean up query objects to omit empty strings/nulls before passing to the API client.
- **Backend**: Use `Optional[str] = None` and manually validate or convert to UUID if it's not empty.

### 4. CORS & Redirects
**Issue:** Browser CORS policy may block redirects (e.g., from `/api/v1/resource` to `/api/v1/resource/`).
**Fix:** Ensure frontend calls ALWAYS include the trailing slash if the backend prefix/router expects it, and ensure `CORSMiddleware` is the outermost middleware.

### 5. Login Response Structure
**Issue:** Simple token-only responses force the frontend to make an extra call to `/me` immediately.
**Fix:** Include the basic `User` object in the login response: `{ "access_token": "...", "user": { "id": "...", "email": "...", "role": "..." } }`.

### 6. Empty Dashboard "Boring" Syndrome
**Issue:** App loads successfully but looks broken/empty because there is no data.
**Fix:** ALWAYS include a seeding step to populate 10-20 realistic records. A "premium" app must look alive on first launch.

### 7. Explicit Type Conversions (The "422" Fix)
**Issue:** Frontend inputs often return empty strings `""` for optional fields, but backends expect `null` or `None`.
**Fix:**
- **Frontend**: `const cleanData = Object.fromEntries(Object.entries(data).map(([k, v]) => [k, v === '' ? null : v]));`
- **Backend (Pydantic)**: Use `@field_validator` to convert `""` to `None`.

### 1. **Requirements Discovery** üîç
- Interactive requirement gathering
- Tech stack recommendations based on project needs
- Infrastructure planning (Docker vs standalone)
- Security architecture design
- Database selection and planning

### 2. **Project Planning** üìã
- Comprehensive project specification generation
- Phase-based breakdown (P0, P1, P2, etc.)
- Folder structure design
- Database schema design
- Architecture documentation

### 3. **Project Bootstrap** üöÄ
- Automated project scaffolding
- Dependency installation
- Configuration setup
- Initial file structure creation
- Development environment setup

### 4. **Phased Implementation** üî®
- Phase-by-phase development
- Automatic testing after each phase
- Gap analysis and remediation
- User approval gates between phases
- Continuous validation

### 5. **Quality Assurance** ‚úÖ
- Automated test suite generation
- Integration testing
- Manual testing documentation
- Feature validation
- Production readiness checklist

---

## EXECUTION PIPELINE

### Stage 1: Discovery & Requirements [INTERACTIVE]

**üìÇ Step 1.0: Context Rehydration (Existing Docs Check)**

**AI Actions:**
1. **Check for `docs/` folder**:
   ```bash
   if [ -d "docs" ]; then
     echo "üìÇ Found existing 'docs/' directory."
     ls -F docs/
     ls -F docs/phases/ 2>/dev/null
   fi
   ```

2. **Resume Logic**:
   - **IF** `docs/project-spec.md` AND `docs/requirements.md` exist:
     - Read these files to understand the project context.
     - **ASK USER**: "I found existing project specifications and phase plans in `docs/`. Would you like to skip discovery and start implementation based on these documents?"
     - **Branching**:
       - **YES**: 
         - Verify `docs/folder-structure.md` exists.
         - Verify `docs/phases/p0-foundation.md` exists.
         - **Jump to Stage 4 (Bootstrap)** or **Stage 5 (Implementation)** immediately.
       - **NO**: Proceed to Step 1.1 (Fresh Start).

**üîç Step 1.1: Initial Discovery**
```bash
# Auto-execute workspace discovery
echo "üìç [1/13] Performing workspace discovery..."
pwd
ls -la
find . -maxdepth 2 -type d -not -path '*/.*' | head -20
```

**Report Format:**
```
‚úÖ Discovery Complete
Workspace: /path/to/project
Status: Empty directory / Existing project detected
Next: Requirements gathering
```

**üéØ Step 1.2: AI-Driven Requirements Analysis (SMART APPROACH)**

**AI Actions:**

1. **Single Comprehensive Question**:
   ```
   üìã Please describe your project in 2-3 sentences:
   
   - What problem does it solve?
   - Who will use it?
   - What are the key features?
   
   Example: "I need a SaaS platform for small businesses to manage their invoices. 
   Users should be able to create, send, and track invoices, with payment integration. 
   It should support multiple team members with different permission levels."
   ```

2. **AI Analysis Process** (Internal - Execute Automatically):
   
   **A) Project Type Detection**:
   - **SaaS Platform**: Keywords like "subscription", "multi-tenant", "dashboard", "analytics", "SaaS"
   - **E-commerce**: Keywords like "shop", "products", "cart", "checkout", "inventory", "store"
   - **CMS/Blog**: Keywords like "content", "articles", "posts", "publishing", "blog"
   - **Internal Dashboard**: Keywords like "admin", "management", "internal", "reporting", "monitor"
   - **REST API**: Keywords like "API", "service", "integration", "webhook", "endpoint"
   - **Mobile Backend**: Keywords like "mobile app", "iOS", "Android", "app backend"
   
   **B) Scale Inference**:
   - **Small** (< 1K users): "personal", "small team", "startup MVP", "prototype"
   - **Medium** (1K-100K users): "growing", "B2B", "SaaS", "business"
   - **Large** (100K+ users): "enterprise", "millions", "high traffic", "scale"
   
   **C) Feature Extraction**:
   - **Auth**: "login", "signup", "user accounts", "authentication"
   - **Payments**: "payment", "subscription", "billing", "Stripe", "checkout"
   - **File Upload**: "upload", "files", "images", "media"
   - **Real-time**: "real-time", "live", "WebSocket", "chat", "notifications"
   - **Search**: "search", "filter", "find"
   - **Analytics**: "analytics", "metrics", "dashboard", "reports"
   - **Multi-tenant**: "multi-tenant", "organizations", "workspaces", "teams"
   - **RBAC**: "roles", "permissions", "admin", "access control"
   
   **D) Tech Stack Auto-Selection**:
   
   **Backend Framework:**
   - **Python + FastAPI**: Data-heavy apps, ML integration, rapid API development
   - **Node.js + Express + TypeScript**: Real-time apps, I/O-heavy, JavaScript ecosystem
   - **Node.js + NestJS**: Enterprise apps, complex architecture, TypeScript-first
   
   **Database:**
   - **PostgreSQL** (Default): Relational data, ACID compliance, JSON support
   - **MongoDB**: Flexible schema, rapid iteration, document storage
   - **SQLite**: Simple projects, prototypes, local-first apps
   
   **Frontend:**
   - **Tailwind + React + TypeScript**: Modern SaaS, dashboards, professional UI (Default for SaaS)
   - **Bootstrap 5 + HTML/React**: Corporate apps, admin panels, traditional (Default for internal tools)
   - **Next.js + Tailwind**: SEO-critical, marketing sites, e-commerce (Default for e-commerce)
   
   **Authentication:**
   - **JWT** (Default): APIs, mobile apps, stateless, scalable
   - **OAuth**: Social login, third-party integrations
   - **Session**: Traditional web apps, server-side rendering
   
   **Infrastructure:**
   - **Docker Compose** (Default): Local development, easy setup
   - **PostgreSQL in Docker** (Default): No external dependencies
   - **Redis**: If caching/real-time features detected

3. **Generate Comprehensive Recommendation**:
   ```markdown
   üéØ AI ANALYSIS COMPLETE
   
   Based on your project description: "[user input]"
   
   I've analyzed this as a **[PROJECT_TYPE]** targeting **[SCALE]** scale.
   
   ---
   
   ## üèóÔ∏è RECOMMENDED ARCHITECTURE
   
   ### Backend
   - **Framework**: [Choice] 
   - **Why**: [Justification based on project needs]
   
   ### Database
   - **Type**: [Choice]
   - **Setup**: PostgreSQL in Docker (no external dependencies needed)
   - **Why**: [Justification]
   
   ### Frontend
   - **Framework**: [Choice]
   - **Styling**: [Tailwind CSS / Bootstrap 5]
   - **Why**: [Justification]
   - **Quality**: Production-ready with animations, responsive design, professional UI
   
   ### Authentication & Security
   - **Auth Method**: [JWT / OAuth / Session]
   - **Authorization**: [RBAC / Custom]
   - **Password Hashing**: bcrypt 4.0.1 (Python 3.12+ compatible)
   - **API Security**: Rate limiting, input validation, CORS
   
   ### Infrastructure
   - **Local Dev**: Docker Compose
   - **Database**: PostgreSQL 15 in Docker
   - **Caching**: [Redis if needed]
   - **Deployment**: Docker-ready, cloud-agnostic
   
   ---
   
   ## ‚ú® AUTO-DETECTED FEATURES
   
   **Phase 0 - Foundation:**
   - [Auto-detected core features]
   
   **Phase 1 - Core Features:**
   - [Auto-detected primary features]
   
   **Phase 2 - Secondary Features:**
   - [Auto-detected nice-to-have features]
   
   **Phase 3 - Advanced Features:**
   - [Auto-detected advanced features]
   
   ---
   
   ## üìä PROJECT ESTIMATES
   
   - **Complexity**: [Simple / Medium / Complex]
   - **Number of Phases**: [N] phases
   
   ---
   
   ## üé® UI/UX APPROACH
   
   - **Design System**: [Tailwind / Bootstrap]
   - **Components**: Production-ready, professionally designed
   - **Animations**: Smooth transitions and micro-interactions
   - **Sample Data**: Realistic mock data (not Lorem Ipsum)
   - **Responsive**: Mobile-first, all screen sizes
   - **Dark Mode**: [Yes/No based on project type]
   
   ---
   
   ‚úÖ **READY TO PROCEED**
   
   This is my recommended approach based on industry best practices and your requirements.
   
   **Your Options:**
   
   1. ‚úÖ **Approve and Start** - I'll begin implementation immediately
   2. üîß **Customize** - Override any choice (e.g., "use MongoDB instead", "add GraphQL")
   3. ‚ùì **Ask Questions** - Get more details about any aspect
   4. üìù **Add Features** - Tell me about additional requirements
   
   What would you like to do?
   ```

4. **Handle User Response**:
   
   **If "Approve"**:
   - Proceed directly to Step 1.3 (Document Requirements)
   - Skip all other questions
   - Use recommended architecture
   
   **If "Customize"**:
   - Parse user's customization request
   - Update specific components
   - Re-present updated recommendation
   - Example: User says "use MongoDB" ‚Üí Update database choice, regenerate recommendation
   
   **If "Questions"**:
   - Answer specific questions
   - Provide detailed justifications
   - Return to options menu
   
   **If "Add Features"**:
   - Incorporate additional features
   - Update phase breakdown
   - Re-present updated recommendation

5. **Optional Follow-up Questions** (Only if CRITICAL info missing):
   
   These are ONLY asked if absolutely necessary:
   
   - "Do you have an existing database server, or should I set one up in Docker?" 
     **(Default: Docker - only ask if user mentions "existing database")**
   
   - "Any specific compliance requirements (GDPR, HIPAA, SOC2)?" 
     **(Default: Basic security - only ask if user mentions "healthcare", "finance", "enterprise")**
   
   - "Preferred cloud provider for deployment guidance?" 
     **(Default: Cloud-agnostic Docker - only ask if user mentions specific cloud)**

**üìù Step 1.3: Document Requirements**
```bash
echo "üìù [2/13] Documenting requirements..."
mkdir -p docs
cat > docs/requirements.md << 'EOF'
# Project Requirements

## Executive Summary
[Auto-generated from user responses]

## Target Users
[User personas and characteristics]

## Core Features
### Must-Have (P0)
- [Feature 1]
- [Feature 2]

### Nice-to-Have (P1-P2)
- [Feature 3]

## Technical Requirements
### Scale
- Users: [number]
- Data: [volume]
- Traffic: [requests/day]

### Security
- Authentication: [method]
- Authorization: [model]
- Compliance: [requirements]

### Infrastructure
- Deployment: [target]
- Database: [type]
- Containerization: [yes/no]
EOF
```

**Output:** 
- ‚úÖ `docs/requirements.md` created
- ‚úÖ User confirmation received
- ‚úÖ Ready for specification phase

---

## üéØ SMART DEFAULTS SYSTEM

### Default Configuration Matrix

**For SaaS Applications:**
```yaml
backend: Node.js + Express + TypeScript
database: PostgreSQL
frontend: React + TypeScript + Tailwind CSS
auth: JWT with refresh tokens
authorization: RBAC
deployment: Docker Compose
features:
  - User authentication
  - Multi-tenant architecture
  - Dashboard with analytics
  - User management
  - Subscription management (if payment keywords detected)
  - Team/workspace management
```

**For E-commerce:**
```yaml
backend: Node.js + Express + TypeScript
database: PostgreSQL
frontend: Next.js + Tailwind CSS (for SEO)
auth: JWT + OAuth (social login)
features:
  - Product catalog with categories
  - Shopping cart
  - Checkout flow
  - Payment integration (Stripe)
  - Order management
  - Inventory tracking
  - Customer accounts
  - Product search and filtering
```

**For CMS/Blog:**
```yaml
backend: Node.js + Express + TypeScript
database: PostgreSQL
frontend: Next.js + Tailwind CSS (for SEO)
auth: JWT
features:
  - Content management (posts, pages)
  - Rich text editor
  - Media management
  - Categories and tags
  - Comments system
  - User profiles
  - SEO optimization
```

**For Internal Dashboards:**
```yaml
backend: Python + FastAPI
database: PostgreSQL
frontend: React + Tailwind CSS
auth: JWT or SSO/LDAP
authorization: RBAC
features:
  - Data visualization
  - Reporting and analytics
  - User management
  - Export functionality (CSV, PDF)
  - Audit logs
  - Real-time monitoring
```

**For REST APIs:**
```yaml
backend: Python + FastAPI or Node.js + Express
database: PostgreSQL
auth: API keys + JWT
features:
  - RESTful endpoints
  - API documentation (Swagger/OpenAPI)
  - Rate limiting
  - Webhook support
  - Request validation
  - Error handling
  - Logging and monitoring
```

**For Mobile Backends:**
```yaml
backend: Node.js + Express + TypeScript
database: PostgreSQL
auth: JWT with refresh tokens
features:
  - User authentication
  - Push notifications
  - File upload/download
  - Real-time sync
  - Offline support considerations
  - API versioning
```

### Override Mechanism

Users can override any default by simply stating:
- "Use MongoDB instead of PostgreSQL"
- "I prefer Vue.js for frontend"
- "Add GraphQL support"
- "Use OAuth for authentication"
- "Skip multi-tenant features"

AI will acknowledge and update the recommendation accordingly.

---

## üîç AUTOMATIC FEATURE DETECTION

### Keyword-Based Feature Mapping

**Authentication & Authorization:**
- "login", "signup", "user accounts" ‚Üí User authentication system
- "admin", "roles", "permissions" ‚Üí RBAC authorization
- "social login", "Google/Facebook" ‚Üí OAuth integration
- "SSO", "LDAP", "Active Directory" ‚Üí Enterprise SSO
- "multi-tenant", "organizations", "workspaces" ‚Üí Multi-tenant architecture

**Data Management:**
- "upload", "files", "images" ‚Üí File storage system (AWS S3/local)
- "export", "CSV", "Excel" ‚Üí Data export functionality
- "import", "bulk upload" ‚Üí Data import system
- "search", "filter" ‚Üí Search functionality (PostgreSQL full-text or Elasticsearch)

**Communication:**
- "email", "notifications" ‚Üí Email system (SendGrid/Nodemailer)
- "SMS", "text messages" ‚Üí SMS integration (Twilio)
- "push notifications" ‚Üí Push notification system (FCM/APNS)
- "chat", "messaging" ‚Üí Real-time chat (WebSocket)

**Payments:**
- "payment", "subscription", "billing" ‚Üí Payment gateway (Stripe)
- "invoice", "receipt" ‚Üí Invoice generation system
- "refund", "cancellation" ‚Üí Payment management

**Analytics & Reporting:**
- "analytics", "metrics", "dashboard" ‚Üí Analytics dashboard
- "reports", "charts", "graphs" ‚Üí Reporting system with visualizations
- "export reports", "PDF" ‚Üí Report generation (PDF/Excel)

**Collaboration:**
- "comments", "feedback" ‚Üí Comment system
- "share", "collaborate" ‚Üí Sharing functionality
- "real-time", "live updates" ‚Üí WebSocket integration
- "notifications", "alerts" ‚Üí Notification system

**E-commerce Specific:**
- "cart", "shopping cart" ‚Üí Shopping cart functionality
- "checkout", "order" ‚Üí Checkout flow
- "inventory", "stock" ‚Üí Inventory management
- "shipping", "delivery" ‚Üí Shipping integration
- "reviews", "ratings" ‚Üí Product review system

### Auto-Phase Assignment

Based on detected features, automatically assign to phases:

**P0 (Foundation):**
- User authentication
- Database setup and migrations
- Basic CRUD operations
- Core infrastructure
- Docker setup

**P1 (Core Features):**
- Primary business logic features
- Main user workflows
- Essential integrations
- Core UI components

**P2 (Secondary Features):**
- Nice-to-have functionality
- Additional user features
- Non-critical integrations
- Enhanced UI/UX

**P3 (Advanced Features):**
- Analytics and reporting
- Advanced search
- Optimization features
- Admin tools
- Advanced integrations

---

### Stage 2: Project Specification [AUTO]

**üìã Step 2.1: Generate Technical Architecture**
```bash
# Check if spec exists first
if [ -f "docs/project-spec.md" ]; then
    echo "‚úÖ Found existing project specification. Reading..."
    cat docs/project-spec.md
    echo "SKIPPING GENERATION based on existing docs."
else
    echo "üèóÔ∏è [3/13] Generating project specification..."
fi
```

**AI Actions (If NO existing spec found):**

1. **Analyze Requirements & Design Architecture**
   ```typescript
   // Auto-generate based on requirements
   const architecture = {
     pattern: 'Monolithic' | 'Microservices' | 'Serverless',
     layers: ['Presentation', 'Business Logic', 'Data Access'],
     communication: 'REST' | 'GraphQL' | 'gRPC',
     caching: 'Redis' | 'Memcached' | 'None',
     queue: 'RabbitMQ' | 'Redis' | 'None'
   };
   ```

2. **Tech Stack Justification**
   ```markdown
   ## Recommended Tech Stack
   
   ### Backend: Node.js + Express + TypeScript
   **Justification:**
   - Fast development with TypeScript type safety
   - Large ecosystem of packages
   - Excellent for I/O-heavy applications
   - Strong community support
   
   ### Database: PostgreSQL
   **Justification:**
   - ACID compliance for data integrity
   - Advanced querying capabilities
   - JSON support for flexible schemas
   - Excellent performance at scale
      ### Frontend: Based on User Preference (Production-Ready Design)
    **Options:**
    
    **A) Tailwind CSS + React + TypeScript** (Recommended for Modern Apps)
    - **Skill Used:** `tailwind-frontend`
    - **Justification:**
      - Utility-first CSS for rapid, custom styling
      - Modern, polished UI components with animations
      - Best-in-class developer experience with Vite + PostCSS
      - Type-safe components with TypeScript
      - Production-ready designs, not mockups
      - Examples: Professional dashboards, stat cards, smooth transitions
      - Ecosystem: shadcn/ui, Radix UI, Lucide icons
    
    **B) Bootstrap 5 + HTML/React** (Recommended for Corporate Apps)
    - **Skill Used:** `bootstrap-frontend`
    - **Justification:**
      - Component-based CSS framework with proven patterns
      - Professional, corporate-friendly designs
      - Quick to prototype with pre-built components
      - Production-ready templates (not basic boilerplate)
      - Examples: Admin panels, data tables, form layouts
      - Ecosystem: Bootstrap Icons, Chart.js
    
    ‚ö†Ô∏è **CRITICAL DESIGN STANDARDS:**
    - ‚úÖ Generate PRODUCTION-READY UI, not mockups or boilerplate
    - ‚úÖ Include professional color schemes (not default blue/gray)
    - ‚úÖ Add smooth animations and micro-interactions
    - ‚úÖ Use realistic sample data (not Lorem Ipsum)
    - ‚úÖ Implement responsive design for all screen sizes
    - ‚úÖ Include proper typography and spacing
    - ‚úÖ Add loading states, empty states, error states
    - ‚ùå NEVER generate basic unstyled forms
    - ‚ùå NEVER use default framework colors without customization
    - ‚ùå NEVER skip animations and transitions
    
    **Frontend Skill Integration:**
    - When user selects Tailwind: Invoke `tailwind-frontend` skill
    - When user selects Bootstrap: Invoke `bootstrap-frontend` skill
    - Both skills generate professional, production-ready components
    - Both skills include sample data and realistic UI states
    ```

3. **Security Architecture Design**
   ```markdown
   ## Security Architecture
   
   ### Authentication
   - Method: JWT with refresh tokens
   - Token expiry: 15 minutes (access), 7 days (refresh)
   - Storage: HttpOnly cookies (web), Secure storage (mobile)
   
   ### Authorization
   - Model: RBAC (Role-Based Access Control)
   - Roles: Admin, Manager, User, Guest
   - Permissions: Resource-based with CRUD operations
   
   ### Data Protection
   - Encryption at rest: AES-256
   - Encryption in transit: TLS 1.3
   - Password hashing: **bcrypt (v4.0.1 for Python 3.12+ stability)** or Argon2
   - Sensitive data: Encrypted columns in database
   
   ### API Security
   - Rate limiting: 100 requests/minute per IP
   - CORS: Whitelist specific origins
   - Input validation: Joi/Zod schemas
   - SQL injection prevention: Parameterized queries
   - XSS protection: Content Security Policy
   ```

4. **Database Schema Design**
   ```sql
   -- Auto-generated based on features
   CREATE TABLE users (
     id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
     email VARCHAR(255) UNIQUE NOT NULL,
     password_hash VARCHAR(255) NOT NULL,
     role VARCHAR(50) NOT NULL DEFAULT 'user',
     created_at TIMESTAMP DEFAULT NOW(),
     updated_at TIMESTAMP DEFAULT NOW()
   );
   
   CREATE INDEX idx_users_email ON users(email);
   CREATE INDEX idx_users_role ON users(role);
   ```

5. **API Design**
   ```yaml
   # Auto-generated REST API specification
   /api/v1:
     /auth:
       POST /register: Register new user
       POST /login: Authenticate user
       POST /refresh: Refresh access token
       POST /logout: Invalidate tokens
     
     /users:
       GET /: List users (admin only)
       GET /:id: Get user details
       PUT /:id: Update user
       DELETE /:id: Delete user
   ```

6. **Folder Structure Design**
   ```
   project-root/
   ‚îú‚îÄ‚îÄ docs/                    # Documentation
   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.md
   ‚îÇ   ‚îú‚îÄ‚îÄ project-spec.md
   ‚îÇ   ‚îú‚îÄ‚îÄ api-docs.md
   ‚îÇ   ‚îî‚îÄ‚îÄ phases/
   ‚îú‚îÄ‚îÄ src/
   ‚îÇ   ‚îú‚îÄ‚îÄ server/             # Backend code
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/         # Configuration
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/     # Express middleware
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/         # API routes
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/    # Request handlers
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/       # Business logic
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/         # Data models
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/          # Utilities
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/          # TypeScript types
   ‚îÇ   ‚îî‚îÄ‚îÄ client/             # Frontend code (if applicable)
   ‚îú‚îÄ‚îÄ tests/
   ‚îÇ   ‚îú‚îÄ‚îÄ unit/
   ‚îÇ   ‚îú‚îÄ‚îÄ integration/
   ‚îÇ   ‚îî‚îÄ‚îÄ e2e/
   ‚îú‚îÄ‚îÄ prisma/                 # Database schema
   ‚îÇ   ‚îî‚îÄ‚îÄ schema.prisma
   ‚îú‚îÄ‚îÄ .env.example
   ‚îú‚îÄ‚îÄ .gitignore
   ‚îú‚îÄ‚îÄ docker-compose.yml
   ‚îú‚îÄ‚îÄ Dockerfile
   ‚îú‚îÄ‚îÄ package.json
   ‚îú‚îÄ‚îÄ tsconfig.json
   ‚îî‚îÄ‚îÄ README.md
   ```

**üìÑ Step 2.2: Generate Specification Document**
```bash
cat > docs/project-spec.md << 'EOF'
# Project Specification

[Auto-generated comprehensive spec with all sections above]
EOF
```

**üë§ Step 2.3: User Review & Approval**
```
üìã PROJECT SPECIFICATION GENERATED

Key Decisions:
- Architecture: [pattern]
- Backend: [stack]
- Frontend: [stack]
- Database: [type]
- Deployment: [method]

Complexity: [Simple/Medium/Complex]

üìñ Full specification saved to: docs/project-spec.md

‚ùì Please review the specification. Approve to proceed with phase planning?
[Wait for user confirmation]
```

**Output:** 
- ‚úÖ `docs/project-spec.md` created
- ‚úÖ User approval received
- ‚úÖ Ready for phase planning

---

### Stage 3: Phase Planning
**AI Actions:**
1. **Check for existing phases**:
   ```bash
   if [ -d "docs/phases" ] && [ "$(ls -A docs/phases)" ]; then
       echo "‚úÖ Found existing phase plans. Verifying..."
       ls -la docs/phases/
       echo "SKIPPING GENERATION based on existing docs."
   else
       # PERFORM GENERATION LOGIC
       echo "üìÖ [4/13] Planning phases..."
       # ... logic to generate phases ...
   fi
   ```

2. **If generating (Fallback)**:
   - Analyze project complexity
   - Break down into phases (P0, P1, P2, P3, etc.):
     - **P0**: Core infrastructure, database, authentication
     - **P1**: Primary features and APIs
     - **P2**: Secondary features and integrations
     - **P3**: Advanced features and optimizations
     - **P4**: Testing, documentation, deployment
   - Create detailed phase documents:
     - Phase objectives
     - Deliverables
     - Acceptance criteria
     - Estimated complexity
   - Generate folder structure document
   - Generate database schema document

**Outputs (Verified or Created):**

**Outputs:**
- `docs/phases/p0-foundation.md`
- `docs/phases/p1-core-features.md`
- `docs/phases/p2-secondary-features.md`
- `docs/phases/p3-advanced-features.md`
- `docs/phases/p4-qa-deployment.md`
- `docs/folder-structure.md`
- `docs/database-schema.md`
- `docs/seed-data-plan.md`

---

### Stage 4: Project Bootstrap
**AI Actions:**
1. Ask user: "Ready to bootstrap the project?"
2. On confirmation:
   - **If `docs/folder-structure.md` exists**: Read it and create folders EXACTLY as specified.
   - **Else**: Create default structure.
   - Create all folders per structure document
   - Generate configuration files:
     - `package.json` / `requirements.txt` / etc.
     - `.env.example`
     - `.gitignore`
     - `docker-compose.yml` (if Docker selected)
     - `Dockerfile` (if Docker selected)
   - Create database schema files
   - Generate initial boilerplate code:
     - Server entry point
     - Database connection
     - Basic middleware
     - Health check endpoint
     - **Seed Script** (`seed.py` or `seed.ts`) enabling realistic data population
   - Install dependencies
   - Initialize git repository
3. **Data Seeding (Crucial for UI/UX)**:
    - If seeding requested:
      - Run: `npm run seed` or `python seed.py`
      - **Verify**: Check that dashboards are NOT empty. An empty dashboard is a failed delivery.
4. Test bootstrap:
   - Verify all files created
   - Check for syntax errors
   - Test server startup
   - Verify database connection

**Output:** Fully bootstrapped project ready for development

---

### Stage 5: Phased Implementation
**AI Actions:**

For each phase (P0 ‚Üí P1 ‚Üí P2 ‚Üí P3 ‚Üí P4):

1. **Announce Phase Start**
   - Display phase objectives
   - List deliverables

2. **Implementation**
   - Create/modify files per phase requirements
   - Follow best practices and patterns
   - Add inline comments explaining changes
   - Implement error handling
   - Add logging

3. **Phase Testing**
   - Run automated tests
   - Test all endpoints/features
   - Verify acceptance criteria
   - Check for errors/warnings

4. **USER UI VERIFICATION (Crucial)**
   - **Check**: Does this phase include UI changes?
   - **IF YES**:
     1. ensure app is running (`npm run dev`)
     2. **Prompt User to Test**:
        ```markdown
        üé® **PHASE [X] UI READY FOR TESTING**
        
        The UI for this phase is ready. Please verify it now:
        
        1. **Open**: http://localhost:3000
        2. **Login** (if auth ready): 
           - Admin: admin@test.com / Admin123!
           - User: user@test.com / User123!
        3. **Test These Features**:
           - [Feature 1 created in this phase]
           - [Feature 2 created in this phase]
        
        Does it look correct?
        ```
     3. **Wait** for user confirmation before proceeding.

5. **Gap Analysis**
   - Compare deliverables vs acceptance criteria
   - Identify missing implementations
   - List any issues found

5. **Gap Remediation**
   - Fix all identified gaps
   - Re-test until all criteria met

6. **Phase Completion Gate**
   - Show phase summary
   - Display test results
   - Ask user: "Phase complete. Continue to next phase?"
   - Allow user override to proceed even with gaps

7. **Move to Next Phase**
   - Only proceed after user approval
   - Repeat process for next phase

**Critical Rules:**
- ‚ùå **NEVER** skip to next phase without completing current phase
- ‚ùå **NEVER** ignore test failures
- ‚úÖ **ALWAYS** prompt user to verify UI changes after EACH phase
- ‚úÖ **ALWAYS** provide test credentials and URL in verification prompts
- ‚úÖ **ALWAYS** wait for user approval before next phase
- ‚úÖ **ALWAYS** document what was implemented
- ‚úÖ **ALWAYS** test thoroughly

---

### Stage 6: Final Validation & Testing
**AI Actions:**

1. **End-to-End Testing**
   - Test complete user flows
   - Verify all integrations
   - Check error handling
   - Validate security measures

2. **Generate Test Suite**
   - Create unit tests
   - Create integration tests
   - Create E2E tests
   - Use appropriate framework (Jest, Pytest, etc.)

3. **Run All Tests**
   - Execute full test suite
   - Report coverage
   - Fix any failures

4. **Manual Testing Documentation**
   - Create `docs/manual-testing-guide.md`
   - Step-by-step testing instructions
   - Expected results for each test
   - Screenshots/examples where helpful
   - Browser testing checklist

5. **Production Readiness Checklist**
   - Environment variables documented
   - Security best practices followed
   - Error handling comprehensive
   - Logging implemented
   - Performance optimized
   - Documentation complete

**Outputs:**
- Complete test suite in `tests/` or `__tests__/`
- `docs/manual-testing-guide.md`
- `docs/production-checklist.md`
- Test coverage report

---

### Stage 7: Automatic Data Seeding & Testing (BEFORE USER HANDOFF)

**Philosophy: NEVER hand over an untested app. Always seed data and verify everything works.**

---

#### Step 1: Create and Run Seed Script

**AI Actions:**

1. **Generate Seed Script** with realistic test data:

**For Node.js (TypeScript):**
```typescript
// scripts/seed.ts
import { PrismaClient } from '@prisma/client';
import bcrypt from 'bcrypt';

const prisma = new PrismaClient();

async function seed() {
  console.log('üå± Seeding database with test data...\n');

  // Create test users with known credentials
  const testUsers = [
    {
      email: 'admin@test.com',
      password: 'Admin123!',
      name: 'Admin User',
      role: 'admin'
    },
    {
      email: 'user@test.com',
      password: 'User123!',
      name: 'Test User',
      role: 'user'
    },
    {
      email: 'demo@test.com',
      password: 'Demo123!',
      name: 'Demo User',
      role: 'user'
    }
  ];

  console.log('Creating test users...');
  for (const user of testUsers) {
    const hashedPassword = await bcrypt.hash(user.password, 10);
    await prisma.user.upsert({
      where: { email: user.email },
      update: {},
      create: {
        email: user.email,
        password: hashedPassword,
        name: user.name,
        role: user.role
      }
    });
    console.log(`‚úÖ Created user: ${user.email}`);
  }

  // Create sample data (e.g., invoices, posts, products, etc.)
  console.log('\nCreating sample data...');
  // ... create 10-20 sample records for each entity
  
  console.log('\n‚úÖ Database seeded successfully!\n');
}

seed()
  .catch(console.error)
  .finally(() => prisma.$disconnect());
```

**For Python (FastAPI):**
```python
# scripts/seed.py
import asyncio
from sqlalchemy.ext.asyncio import AsyncSession
from database import engine, get_db
from models import User
from auth import hash_password

async def seed():
    print("üå± Seeding database with test data...\n")
    
    async with AsyncSession(engine) as session:
        # Create test users
        test_users = [
            {
                "email": "admin@test.com",
                "password": "Admin123!",
                "name": "Admin User",
                "role": "admin"
            },
            {
                "email": "user@test.com",
                "password": "User123!",
                "name": "Test User",
                "role": "user"
            },
            {
                "email": "demo@test.com",
                "password": "Demo123!",
                "name": "Demo User",
                "role": "user"
            }
        ]
        
        print("Creating test users...")
        for user_data in test_users:
            user = User(
                email=user_data["email"],
                password=hash_password(user_data["password"]),
                name=user_data["name"],
                role=user_data["role"]
            )
            session.add(user)
            print(f"‚úÖ Created user: {user_data['email']}")
        
        await session.commit()
        
        # Create sample data
        print("\nCreating sample data...")
        # ... create 10-20 sample records
        
        print("\n‚úÖ Database seeded successfully!\n")

if __name__ == "__main__":
    asyncio.run(seed())
```

2. **Add seed command to package.json:**
```json
{
  "scripts": {
    "seed": "ts-node scripts/seed.ts",
    "seed:fresh": "npm run db:reset && npm run seed"
  }
}
```

3. **Run seeding automatically:**
```bash
echo "üå± Seeding database with test data..."
npm run seed

# Verify seeding worked
echo "Verifying seed data..."
# Check database has records
```

---

#### Step 2: Automatic Testing (Before User Handoff)

**AI Actions:**

1. **Start the application:**
```bash
# Start backend
npm run dev &
BACKEND_PID=$!

# Wait for backend to be ready
sleep 5

# Start frontend (if applicable)
cd client && npm run dev &
FRONTEND_PID=$!

# Wait for frontend to be ready
sleep 10
```

2. **Run automated tests:**
```bash
echo "üß™ Running automated tests..."

# Test 1: Health check
curl -s http://localhost:4000/health | jq

# Test 2: User registration
curl -X POST http://localhost:4000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"Test123!","name":"Test"}'

# Test 3: User login (with seeded credentials)
LOGIN_RESPONSE=$(curl -X POST http://localhost:4000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@test.com","password":"Admin123!"}')

TOKEN=$(echo $LOGIN_RESPONSE | jq -r '.access_token')

# Test 4: Protected endpoint
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:4000/api/users/me

# Test 5: Main features
# ... test each core feature
```

3. **Verify UI loads:**
```bash
# Check if frontend is accessible
curl -s http://localhost:3000 > /dev/null && echo "‚úÖ Frontend accessible"

# Take screenshot (if possible)
# Open browser for visual verification
```

---

#### Step 3: User Handoff with Complete Details

**AI Presents:**

```markdown
üéâ **YOUR APPLICATION IS READY!**

I've built, tested, and verified everything. Here's how to use it:

---

## üöÄ START THE APPLICATION

**Run this command:**
```bash
npm run dev
```

**What you'll see:**
```
‚úÖ Server running on http://localhost:4000
‚úÖ Frontend running on http://localhost:3000
‚úÖ Database connected
```

**Wait 10-15 seconds for everything to start, then continue below.**

---

## üåê OPEN YOUR APPLICATION

**Click this link or copy to your browser:**
üëâ **http://localhost:3000**

**You should see:** Your application's home page with login/signup options

---

## üîê TEST LOGIN (I've already created test accounts for you!)

**Use these credentials to login:**

### Admin Account
- **Email:** `admin@test.com`
- **Password:** `Admin123!`
- **Access:** Full admin privileges

### Regular User Account
- **Email:** `user@test.com`
- **Password:** `User123!`
- **Access:** Standard user access

### Demo Account
- **Email:** `demo@test.com`
- **Password:** `Demo123!`
- **Access:** Demo/guest access

**To test login:**
1. Open http://localhost:3000
2. Click "Login"
3. Enter one of the emails above
4. Enter the corresponding password
5. Click "Sign In"
6. ‚úÖ You should be redirected to the dashboard

---

## ‚úÖ WHAT I'VE ALREADY TESTED

I've automatically verified:
- ‚úÖ Database connection working
- ‚úÖ All API endpoints responding
- ‚úÖ User registration working
- ‚úÖ User login working (tested with admin@test.com)
- ‚úÖ Authentication tokens working
- ‚úÖ Protected routes working
- ‚úÖ Frontend builds successfully
- ‚úÖ Sample data loaded (10+ records)

**All tests passed!** Your app is production-ready.

---

## üé® EXPLORE THE UI

**I strongly encourage you to:**
1. ‚úÖ Login with the test accounts above
2. ‚úÖ Click around and explore all features
3. ‚úÖ Try creating new records
4. ‚úÖ Test the main workflows
5. ‚úÖ Check the dashboard/analytics
6. ‚úÖ Verify everything looks good

**This is important!** Visual testing helps catch UI issues that automated tests miss.

---

## üìä SAMPLE DATA INCLUDED

I've pre-loaded your database with realistic test data:
- 3 test user accounts (credentials above)
- 10-15 sample [invoices/posts/products/etc.]
- Sample categories/tags
- Realistic timestamps and relationships

**Why?** So your app looks alive and professional, not empty and broken.

---

## üß™ API TESTING (Optional)

**If you want to test the API directly:**

**Health Check:**
```bash
curl http://localhost:4000/health
```

**Login:**
```bash
curl -X POST http://localhost:4000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@test.com","password":"Admin123!"}'
```

**Get User Profile:**
```bash
# First login to get token, then:
curl -H "Authorization: Bearer YOUR_TOKEN" \
  http://localhost:4000/api/users/me
```

---

## üìÅ PROJECT STRUCTURE

Your project is organized as:
```
project/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ server/          # Backend code
‚îÇ   ‚îú‚îÄ‚îÄ client/          # Frontend code
‚îÇ   ‚îî‚îÄ‚îÄ database/        # Database schemas
‚îú‚îÄ‚îÄ tests/               # Automated tests
‚îú‚îÄ‚îÄ docs/                # Documentation
‚îú‚îÄ‚îÄ scripts/             # Utility scripts (including seed.ts)
‚îî‚îÄ‚îÄ .env                 # Environment variables
```

---

## üîÑ USEFUL COMMANDS

**Start development:**
```bash
npm run dev
```

**Run tests:**
```bash
npm test
```

**Seed database:**
```bash
npm run seed
```

**Reset database:**
```bash
npm run db:reset && npm run seed
```

**Build for production:**
```bash
npm run build
```

---

## üöÄ NEXT STEPS

1. ‚úÖ **Test the app** - Login and explore the UI
2. ‚úÖ **Verify features** - Make sure everything works as expected
3. ‚úÖ **Customize** - Add your own data, tweak the UI
4. ‚úÖ **Deploy** - When ready, I can guide you through deployment

**Ready to deploy?** Just say "Let's deploy" and I'll provide step-by-step guides for:
- Vercel (frontend) - Free, 5 minutes
- Railway (backend) - Free $5/month, 10 minutes
- Supabase (database) - Free 500MB, 5 minutes

---

## üí° TROUBLESHOOTING

**If the app doesn't start:**
```bash
# Make sure dependencies are installed
npm install

# Make sure database is running
docker-compose up -d

# Check for errors in terminal
```

**If you can't login:**
- Make sure you're using the exact credentials above
- Check that the database is running
- Verify the app is fully started (wait 15 seconds)

**If you see errors:**
- Check the terminal for error messages
- Make sure ports 3000 and 4000 are not in use
- Try restarting: `npm run dev`

---

## üéâ YOU'RE ALL SET!

Your application is **fully functional** and **production-ready**.

**What to do now:**
1. Open http://localhost:3000
2. Login with admin@test.com / Admin123!
3. Explore and enjoy!

Questions? Just ask! üòä
```

---

#### Step 4: Open Browser Automatically (If Possible)

**AI Actions:**

```bash
# Try to open browser automatically
if command -v open &> /dev/null; then
    # macOS
    open http://localhost:3000
elif command -v xdg-open &> /dev/null; then
    # Linux
    xdg-open http://localhost:3000
elif command -v start &> /dev/null; then
    # Windows
    start http://localhost:3000
fi

echo "üåê Opening http://localhost:3000 in your browser..."
echo "If it doesn't open automatically, click the link above!"
```

---

### Critical Rules for User Handoff

**‚úÖ ALWAYS DO:**
1. ‚úÖ Seed database with test data BEFORE handoff
2. ‚úÖ Create test user accounts with known passwords
3. ‚úÖ Run automated tests to verify everything works
4. ‚úÖ Test login functionality specifically
5. ‚úÖ Provide complete URLs and commands
6. ‚úÖ Include test credentials prominently
7. ‚úÖ Encourage UI testing ("Open and explore!")
8. ‚úÖ Pre-load sample data so app looks alive
9. ‚úÖ Try to open browser automatically
10. ‚úÖ Provide troubleshooting steps

**‚ùå NEVER DO:**
1. ‚ùå Hand over an empty database
2. ‚ùå Skip testing login functionality
3. ‚ùå Provide vague instructions
4. ‚ùå Show time estimates to user
5. ‚ùå Assume user knows how to test
6. ‚ùå Hand over without verifying it works
7. ‚ùå Forget to provide test credentials

---

---

## üß™ AUTOMATED TESTING & VERIFICATION (Non-Technical Users)

### Philosophy
**Non-technical users should NOT need to know how to test manually. We automate everything possible.**

---

### Step 1: Create Automated Verification Scripts

**AI Actions:**

1. **For Node.js Projects**, create `scripts/verify-project.js`:
```javascript
// Auto-generated verification script
const axios = require('axios');
const chalk = require('chalk');

async function verifyProject() {
  console.log(chalk.blue('\nüß™ Running Automated Verification...\n'));
  
  const checks = [];
  
  // Check 1: Environment Variables
  console.log('Checking environment variables...');
  const requiredEnvVars = ['DATABASE_URL', 'JWT_SECRET', 'PORT'];
  const missingVars = requiredEnvVars.filter(v => !process.env[v]);
  
  if (missingVars.length === 0) {
    console.log(chalk.green('‚úÖ All environment variables set'));
    checks.push(true);
  } else {
    console.log(chalk.red(`‚ùå Missing: ${missingVars.join(', ')}`));
    checks.push(false);
  }
  
  // Check 2: Database Connection
  console.log('\nChecking database connection...');
  try {
    // Test database connection
    await testDatabaseConnection();
    console.log(chalk.green('‚úÖ Database connected successfully'));
    checks.push(true);
  } catch (error) {
    console.log(chalk.red('‚ùå Database connection failed'));
    console.log(chalk.yellow(`   Error: ${error.message}`));
    checks.push(false);
  }
  
  // Check 3: API Endpoints
  console.log('\nChecking API endpoints...');
  const endpoints = [
    { method: 'GET', path: '/health', name: 'Health Check' },
    { method: 'POST', path: '/api/auth/register', name: 'Registration' },
    { method: 'POST', path: '/api/auth/login', name: 'Login' }
  ];
  
  for (const endpoint of endpoints) {
    try {
      const response = await axios[endpoint.method.toLowerCase()](
        `http://localhost:${process.env.PORT}${endpoint.path}`
      );
      console.log(chalk.green(`‚úÖ ${endpoint.name} working`));
      checks.push(true);
    } catch (error) {
      console.log(chalk.red(`‚ùå ${endpoint.name} failed`));
      checks.push(false);
    }
  }
  
  // Check 4: Frontend Build
  console.log('\nChecking frontend build...');
  try {
    const { execSync } = require('child_process');
    execSync('npm run build --prefix client', { stdio: 'ignore' });
    console.log(chalk.green('‚úÖ Frontend builds successfully'));
    checks.push(true);
  } catch (error) {
    console.log(chalk.red('‚ùå Frontend build failed'));
    checks.push(false);
  }
  
  // Summary
  console.log(chalk.blue('\nüìä VERIFICATION SUMMARY\n'));
  const passed = checks.filter(c => c).length;
  const total = checks.length;
  
  if (passed === total) {
    console.log(chalk.green(`üéâ All checks passed! (${passed}/${total})`));
    console.log(chalk.green('\n‚úÖ Your project is ready to use!\n'));
  } else {
    console.log(chalk.yellow(`‚ö†Ô∏è  ${passed}/${total} checks passed`));
    console.log(chalk.yellow('\nPlease fix the issues above before deploying.\n'));
  }
}

verifyProject().catch(console.error);
```

2. **For Python Projects**, create `scripts/verify_project.py`:
```python
#!/usr/bin/env python3
import os
import sys
import requests
from colorama import Fore, Style, init

init(autoreset=True)

def verify_project():
    print(f"\n{Fore.BLUE}üß™ Running Automated Verification...\n")
    
    checks = []
    
    # Check 1: Environment Variables
    print("Checking environment variables...")
    required_vars = ['DATABASE_URL', 'JWT_SECRET', 'PORT']
    missing_vars = [v for v in required_vars if not os.getenv(v)]
    
    if not missing_vars:
        print(f"{Fore.GREEN}‚úÖ All environment variables set")
        checks.append(True)
    else:
        print(f"{Fore.RED}‚ùå Missing: {', '.join(missing_vars)}")
        checks.append(False)
    
    # Check 2: Database Connection
    print("\nChecking database connection...")
    try:
        from database import test_connection
        test_connection()
        print(f"{Fore.GREEN}‚úÖ Database connected successfully")
        checks.append(True)
    except Exception as e:
        print(f"{Fore.RED}‚ùå Database connection failed")
        print(f"{Fore.YELLOW}   Error: {str(e)}")
        checks.append(False)
    
    # Check 3: API Endpoints
    print("\nChecking API endpoints...")
    port = os.getenv('PORT', '8000')
    endpoints = [
        {'method': 'GET', 'path': '/health', 'name': 'Health Check'},
        {'method': 'POST', 'path': '/api/auth/register', 'name': 'Registration'},
        {'method': 'POST', 'path': '/api/auth/login', 'name': 'Login'}
    ]
    
    for endpoint in endpoints:
        try:
            url = f"http://localhost:{port}{endpoint['path']}"
            response = requests.request(endpoint['method'], url, timeout=5)
            print(f"{Fore.GREEN}‚úÖ {endpoint['name']} working")
            checks.append(True)
        except Exception:
            print(f"{Fore.RED}‚ùå {endpoint['name']} failed")
            checks.append(False)
    
    # Summary
    print(f"\n{Fore.BLUE}üìä VERIFICATION SUMMARY\n")
    passed = sum(checks)
    total = len(checks)
    
    if passed == total:
        print(f"{Fore.GREEN}üéâ All checks passed! ({passed}/{total})")
        print(f"{Fore.GREEN}\n‚úÖ Your project is ready to use!\n")
    else:
        print(f"{Fore.YELLOW}‚ö†Ô∏è  {passed}/{total} checks passed")
        print(f"{Fore.YELLOW}\nPlease fix the issues above before deploying.\n")

if __name__ == '__main__':
    verify_project()
```

3. **Add to package.json** (Node.js):
```json
{
  "scripts": {
    "verify": "node scripts/verify-project.js",
    "test:all": "npm run verify && npm test"
  }
}
```

---

### Step 2: Create Beginner-Friendly Testing Guide

**AI Creates `docs/how-to-test.md`:**

```markdown
# How to Test Your Application (Non-Technical Guide)

## üéØ What is Testing?

Testing means checking if your application works correctly. Think of it like test-driving a car before buying it.

---

## üìã Quick Start (Automated)

**The easiest way to test everything:**

```bash
npm run verify
```

**What this does:**
- ‚úÖ Checks if all required settings are configured
- ‚úÖ Tests database connection
- ‚úÖ Tests all API endpoints
- ‚úÖ Verifies the frontend builds correctly

**Expected output:**
```
üß™ Running Automated Verification...

‚úÖ All environment variables set
‚úÖ Database connected successfully
‚úÖ Health Check working
‚úÖ Registration working
‚úÖ Login working
‚úÖ Frontend builds successfully

üéâ All checks passed! (6/6)
‚úÖ Your project is ready to use!
```

---

## üñ•Ô∏è Manual Testing (Step-by-Step)

### Step 1: Start the Application

**Open your terminal and run:**
```bash
npm run dev
```

**What you'll see:**
```
Server running on http://localhost:4000
Frontend running on http://localhost:3000
Database connected ‚úÖ
```

**What this means:**
Your application is now running on your computer. You can access it in your web browser.

**If you see an error:**
- Check the troubleshooting section below
- Make sure you ran `npm install` first
- Verify your `.env` file exists

---

### Step 2: Open in Browser

1. Open your web browser (Chrome, Firefox, or Safari)
2. Go to: **http://localhost:3000**
3. You should see your application's home page

**Expected result:**
- ‚úÖ Page loads without errors
- ‚úÖ You see the login/signup page
- ‚úÖ No error messages in the browser console

**If the page doesn't load:**
- Wait 10-15 seconds (first load can be slow)
- Refresh the page (F5 or Cmd+R)
- Check the terminal for error messages

---

### Step 3: Test User Registration

**What to do:**
1. Click the **"Sign Up"** or **"Register"** button
2. Fill in the form:
   - Email: `test@example.com`
   - Password: `Test123!`
   - Name: `Test User`
3. Click **"Create Account"**

**Expected result:**
- ‚úÖ Success message appears
- ‚úÖ You're redirected to the dashboard or login page
- ‚úÖ No error messages

**If it doesn't work:**
- Check if email is already registered
- Make sure password meets requirements
- Check browser console for errors (F12)

---

### Step 4: Test Login

**What to do:**
1. Go to the login page
2. Enter your credentials:
   - Email: `test@example.com`
   - Password: `Test123!`
3. Click **"Sign In"**

**Expected result:**
- ‚úÖ Success message appears
- ‚úÖ You're redirected to the dashboard
- ‚úÖ You see your name or email displayed

**If it doesn't work:**
- Double-check your email and password
- Make sure you registered first
- Try resetting your password

---

### Step 5: Test Main Features

**For each feature in your app, follow this pattern:**

1. **Navigate to the feature** (e.g., "Create Invoice")
2. **Fill in the form** with test data
3. **Submit the form**
4. **Verify the result** (success message, data appears)

**Example: Creating an Invoice**
1. Click **"New Invoice"**
2. Fill in:
   - Customer: `Test Customer`
   - Amount: `$100.00`
   - Due Date: `Tomorrow's date`
3. Click **"Create Invoice"**
4. ‚úÖ Invoice appears in the list

---

## üîç What to Look For

### ‚úÖ Good Signs:
- Pages load quickly (under 3 seconds)
- Forms submit successfully
- Data appears after creation
- No error messages
- Buttons and links work
- Images load correctly

### ‚ùå Bad Signs:
- Error messages appear
- Pages don't load
- Forms don't submit
- Data doesn't save
- Buttons don't respond
- Blank pages

---

## üêõ Common Issues & Solutions

### Issue: "Cannot connect to database"

**Solution:**
```bash
# Make sure Docker is running
docker ps

# If not, start it:
docker-compose up -d

# Wait 10 seconds, then try again
```

---

### Issue: "Port 3000 already in use"

**Solution:**
```bash
# Find what's using the port
lsof -i :3000

# Stop it (replace PID with the number shown)
kill -9 PID

# Or use a different port
PORT=3001 npm run dev
```

---

### Issue: "Module not found"

**Solution:**
```bash
# Reinstall dependencies
npm install

# Clear cache and reinstall
rm -rf node_modules
npm install
```

---

## üì± Testing on Different Devices

### Desktop Browser
- ‚úÖ Chrome (recommended)
- ‚úÖ Firefox
- ‚úÖ Safari
- ‚úÖ Edge

### Mobile (Optional)
1. Find your computer's IP address:
   ```bash
   # Mac/Linux
   ifconfig | grep "inet "
   
   # Windows
   ipconfig
   ```
2. On your phone, go to: `http://YOUR_IP:3000`
3. Test the same features

---

## ‚úÖ Testing Checklist

Before deploying, make sure:

- [ ] Automated verification passes (`npm run verify`)
- [ ] User registration works
- [ ] User login works
- [ ] All main features work
- [ ] Forms validate correctly
- [ ] Error messages are clear
- [ ] Data persists after refresh
- [ ] Logout works
- [ ] No console errors
- [ ] Mobile responsive (optional)

---

## üéâ Next Steps

Once all tests pass:
1. ‚úÖ Your app is ready for deployment
2. üìñ See the deployment guide: `docs/deployment-guide.md`
3. üöÄ Choose a platform (Vercel, Railway, etc.)
4. üåê Deploy and share with users!

---

## üí° Need Help?

If you're stuck:
1. Check the error message carefully
2. Look in the troubleshooting section
3. Check the terminal output
4. Search the error message online
5. Ask for help with the specific error message
```

---

### Step 3: Run Automated Verification

**AI Actions After Implementation:**

```bash
echo "üß™ Running automated verification..."
npm run verify

# Or for Python
python scripts/verify_project.py
```

**Present Results to User:**
```markdown
‚úÖ VERIFICATION COMPLETE

**Results:**
- Database Connection: ‚úÖ Connected successfully
- API Endpoints: ‚úÖ All 12 endpoints working
- Frontend Build: ‚úÖ Build successful (2.3 MB)
- Environment Variables: ‚úÖ All required variables set
- Security Checks: ‚úÖ No vulnerabilities found
- Performance: ‚úÖ Average response time: 45ms

üéâ Your project is ready to use!

**What to do next:**

1. **Test it yourself:**
   - Open http://localhost:3000 in your browser
   - Follow the testing guide: `docs/how-to-test.md`

2. **Deploy to production:**
   - See deployment guide: `docs/deployment-guide.md`
   - I recommend Vercel (frontend) + Railway (backend)

3. **Share with users:**
   - Once deployed, share your live URL
   - Monitor usage in platform dashboards

Would you like me to guide you through deployment?
```

---

## üöÄ DEPLOYMENT GUIDES (Non-Technical Friendly)

### Platform Recommendations & Comparison

**AI Analysis:**
Based on your project type, here are the best deployment platforms:

| Platform | Best For | Free Tier | Difficulty | Setup Time | Database Included |
|----------|----------|-----------|------------|------------|-------------------|
| **Vercel** | Frontend, Next.js | ‚úÖ Generous (100GB bandwidth) | ‚≠ê Easy | 5 min | ‚ùå (use Supabase) |
| **Railway** | Full-stack apps | ‚úÖ $5/month credit | ‚≠ê‚≠ê Medium | 10 min | ‚úÖ PostgreSQL |
| **Render** | Backend + Database | ‚úÖ Limited (750 hrs/month) | ‚≠ê‚≠ê Medium | 15 min | ‚úÖ PostgreSQL |
| **Fly.io** | Docker apps | ‚úÖ Limited (3 VMs) | ‚≠ê‚≠ê‚≠ê Advanced | 20 min | ‚úÖ PostgreSQL |
| **Supabase** | Database + Auth | ‚úÖ Generous (500MB DB) | ‚≠ê Easy | 5 min | ‚úÖ PostgreSQL |
| **Netlify** | Static sites, Jamstack | ‚úÖ Generous (100GB bandwidth) | ‚≠ê Easy | 5 min | ‚ùå |
| **Heroku** | Full-stack apps | ‚ùå No free tier (paid only) | ‚≠ê‚≠ê Medium | 15 min | ‚úÖ PostgreSQL |

**My Recommendation for Your Project:**

**For SaaS/Full-Stack Apps:**
- **Frontend**: Vercel (free, easy, perfect for React/Next.js)
- **Backend**: Railway (free $5/month, supports PostgreSQL, easy setup)
- **Database**: Included with Railway OR use Supabase (more generous limits)

**For Static Sites/Landing Pages:**
- **Hosting**: Vercel or Netlify (both excellent, free, easy)
- **CMS**: Supabase (if you need a database)

**For API-Only Projects:**
- **Backend**: Railway or Render (both include database)
- **Database**: Included OR use Supabase separately

---

### üìò Deployment Guide: Vercel (Frontend)

**Best for:** React, Next.js, Vue, Static sites  
**Free tier:** 100GB bandwidth, unlimited projects  
**Setup time:** 5 minutes

---

#### Step 1: Create Vercel Account

1. Go to [https://vercel.com](https://vercel.com)
2. Click **"Sign Up"**
3. Choose **"Continue with GitHub"** (recommended)
4. Authorize Vercel to access your GitHub

**Why GitHub?** Vercel will automatically deploy when you push code to GitHub.

---

#### Step 2: Prepare Your Project

**AI will create `vercel.json` for you:**
```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "devCommand": "npm run dev",
  "installCommand": "npm install"
}
```

**For Next.js projects:** No configuration needed! Vercel auto-detects.

---

#### Step 3: Deploy from GitHub

1. Push your code to GitHub:
   ```bash
   git add .
   git commit -m "Ready for deployment"
   git push origin main
   ```

2. Go to [https://vercel.com/new](https://vercel.com/new)
3. Click **"Import Project"**
4. Select your GitHub repository
5. Vercel auto-detects settings ‚úÖ
6. Click **"Deploy"**

---

#### Step 4: Configure Environment Variables

**In Vercel Dashboard:**
1. Go to your project ‚Üí **Settings** ‚Üí **Environment Variables**
2. Add each variable:

```
NEXT_PUBLIC_API_URL = https://your-backend.railway.app
NEXT_PUBLIC_STRIPE_KEY = pk_live_...
```

**AI will provide all required variables in a file: `deployment/vercel-env.txt`**

---

#### Step 5: Custom Domain (Optional)

1. Go to **Settings** ‚Üí **Domains**
2. Add your domain (e.g., `myapp.com`)
3. Update DNS records (Vercel provides instructions)
4. Wait 5-10 minutes for DNS propagation

---

**‚úÖ Deployment Complete!**

Your app is live at: `https://your-app.vercel.app`

**Automatic Updates:** Every time you push to GitHub, Vercel auto-deploys! üéâ

---

### üìò Deployment Guide: Railway (Backend + Database)

**Best for:** Node.js, Python, Go backends with PostgreSQL  
**Free tier:** $5/month credit (enough for small apps)  
**Setup time:** 10 minutes

---

#### Step 1: Create Railway Account

1. Go to [https://railway.app](https://railway.app)
2. Click **"Login with GitHub"**
3. Authorize Railway
4. You get **$5 free credit every month** üéâ

---

#### Step 2: Prepare Your Project

**AI will create `railway.json` for you:**
```json
{
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "npm start",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

**For Python projects:**
```json
{
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "gunicorn main:app",
    "restartPolicyType": "ON_FAILURE"
  }
}
```

---

#### Step 3: Deploy from GitHub

1. Push your code to GitHub:
   ```bash
   git add .
   git commit -m "Ready for deployment"
   git push origin main
   ```

2. Go to [https://railway.app/new](https://railway.app/new)
3. Click **"Deploy from GitHub repo"**
4. Select your repository
5. Railway auto-detects your app ‚úÖ

---

#### Step 4: Add PostgreSQL Database

1. In your Railway project, click **"New"**
2. Select **"Database"** ‚Üí **"PostgreSQL"**
3. Railway creates the database instantly ‚úÖ
4. Connection string is auto-configured as `DATABASE_URL` ‚úÖ

**No manual setup needed!** Railway automatically connects your app to the database.

---

#### Step 5: Configure Environment Variables

**In Railway Dashboard:**
1. Click on your service
2. Go to **"Variables"** tab
3. Add variables:

```
DATABASE_URL = (auto-set by Railway)
JWT_SECRET = your-secret-key-here
FRONTEND_URL = https://your-app.vercel.app
PORT = (auto-set by Railway)
```

**AI will provide all required variables in: `deployment/railway-env.txt`**

---

#### Step 6: Generate Domain

1. Click on your service
2. Go to **"Settings"** tab
3. Click **"Generate Domain"**
4. Railway provides: `your-app.up.railway.app`

---

**‚úÖ Deployment Complete!**

Your API is live at: `https://your-app.up.railway.app`

**Automatic Updates:** Every push to GitHub auto-deploys! üéâ

---

### üìò Deployment Guide: Supabase (Database + Auth)

**Best for:** PostgreSQL database, Authentication, Storage  
**Free tier:** 500MB database, 50,000 monthly active users  
**Setup time:** 5 minutes

---

#### Step 1: Create Supabase Project

1. Go to [https://supabase.com](https://supabase.com)
2. Click **"Start your project"**
3. Sign in with GitHub
4. Click **"New project"**
5. Fill in:
   - **Name**: `my-app-db`
   - **Database Password**: (generate strong password)
   - **Region**: Choose closest to your users
6. Click **"Create new project"**
7. Wait 2 minutes for setup ‚è≥

---

#### Step 2: Get Database Connection String

1. Go to **Settings** ‚Üí **Database**
2. Scroll to **"Connection string"**
3. Select **"URI"**
4. Copy the connection string:
   ```
   postgresql://postgres:[YOUR-PASSWORD]@db.xxx.supabase.co:5432/postgres
   ```

---

#### Step 3: Update Your Application

**AI will update your `.env` file:**
```bash
DATABASE_URL=postgresql://postgres:[YOUR-PASSWORD]@db.xxx.supabase.co:5432/postgres
```

---

#### Step 4: Run Database Migrations

**AI will create a migration script:**
```bash
# For Node.js (Prisma)
npx prisma migrate deploy

# For Python (Alembic)
alembic upgrade head

# Or use Supabase SQL Editor
```

**In Supabase Dashboard:**
1. Go to **SQL Editor**
2. Paste your schema SQL
3. Click **"Run"**

---

#### Step 5: Setup Authentication (Optional)

**If using Supabase Auth:**

1. Go to **Authentication** ‚Üí **Providers**
2. Enable **Email** provider
3. Copy your API keys:
   - **Project URL**: `https://xxx.supabase.co`
   - **Anon Key**: `eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...`

**AI will configure your app to use Supabase Auth**

---

**‚úÖ Database Ready!**

Your database is live and accessible from anywhere!

**Connection string:** Use in Railway, Vercel, or local development

---

### üìò Deployment Guide: Render (Full-Stack Alternative)

**Best for:** Full-stack apps, Docker, Background workers  
**Free tier:** 750 hours/month (enough for one app)  
**Setup time:** 15 minutes

---

#### Step 1: Create Render Account

1. Go to [https://render.com](https://render.com)
2. Click **"Get Started"**
3. Sign up with GitHub

---

#### Step 2: Deploy Web Service

1. Click **"New"** ‚Üí **"Web Service"**
2. Connect your GitHub repository
3. Configure:
   - **Name**: `my-app-backend`
   - **Environment**: `Node` or `Python`
   - **Build Command**: `npm install` or `pip install -r requirements.txt`
   - **Start Command**: `npm start` or `gunicorn main:app`
   - **Plan**: **Free**

---

#### Step 3: Add PostgreSQL Database

1. Click **"New"** ‚Üí **"PostgreSQL"**
2. Configure:
   - **Name**: `my-app-db`
   - **Plan**: **Free**
3. Click **"Create Database"**
4. Copy **Internal Database URL**

---

#### Step 4: Connect Database to Web Service

1. Go to your web service
2. **Environment** ‚Üí **Add Environment Variable**
3. Add:
   ```
   DATABASE_URL = [paste internal database URL]
   ```

---

**‚úÖ Deployment Complete!**

Your app is live at: `https://my-app-backend.onrender.com`

**Note:** Free tier apps sleep after 15 minutes of inactivity (first request takes ~30 seconds to wake up)

---

### üîß Prerequisites & Troubleshooting

#### Automated Prerequisites Check

**AI will run this automatically:**

```bash
#!/bin/bash
echo "üîç Checking prerequisites..."

# Check Node.js
if ! command -v node &> /dev/null; then
    echo "‚ùå Node.js not found"
    echo "üì• Install from: https://nodejs.org/"
    echo "   Or use alternative: GitHub Codespaces (no installation needed)"
    echo ""
    echo "Would you like to:"
    echo "1. Install Node.js locally"
    echo "2. Use GitHub Codespaces (cloud-based, no installation)"
    echo "3. Use Replit (browser-based IDE)"
else
    echo "‚úÖ Node.js $(node --version) found"
fi

# Check Docker
if ! command -v docker &> /dev/null; then
    echo "‚ö†Ô∏è  Docker not found"
    echo ""
    echo "No problem! You have 3 options:"
    echo ""
    echo "Option 1: Install Docker (Recommended)"
    echo "  - Download: https://www.docker.com/get-started"
    echo "  - Takes 5 minutes to install"
    echo "  - Best for local development"
    echo ""
    echo "Option 2: Use Cloud Database (No Installation)"
    echo "  - I can set up a free PostgreSQL database on Supabase"
    echo "  - No Docker needed"
    echo "  - Just say: 'Use Supabase database'"
    echo ""
    echo "Option 3: Use SQLite (Simplest)"
    echo "  - No installation needed"
    echo "  - Works immediately"
    echo "  - Good for testing, not for production"
    echo "  - Just say: 'Use SQLite instead'"
    echo ""
    read -p "Which option would you prefer? (1/2/3): " choice
else
    echo "‚úÖ Docker $(docker --version) found"
fi

# Check Git
if ! command -v git &> /dev/null; then
    echo "‚ùå Git not found"
    echo "üì• Install from: https://git-scm.com/"
else
    echo "‚úÖ Git $(git --version) found"
fi

echo ""
echo "‚úÖ Prerequisites check complete!"
```

---

#### Common Issues & Solutions

**Issue: "Docker is not available"**

**AI Response:**
```markdown
No problem! You have 3 options:

**Option 1: Install Docker (Recommended)**
- Download: https://www.docker.com/get-started
- Takes 5 minutes to install
- Easiest for local development
- Works on Mac, Windows, Linux

**Option 2: Use Cloud Database (No Installation)**
- I can set up a free PostgreSQL database on Supabase
- No Docker needed
- Takes 5 minutes
- Free tier: 500MB database
- Just say: "Use Supabase database"

**Option 3: Use SQLite (Simplest)**
- No installation needed
- Works immediately
- Good for testing, not recommended for production
- Just say: "Use SQLite instead"

Which option would you prefer?
```

---

**Issue: "Port already in use"**

**AI Response:**
```markdown
Another application is using port 3000. Here's how to fix it:

**Option 1: Stop the other application**
```bash
# Find what's using the port
lsof -i :3000

# Stop it (replace PID with the number shown)
kill -9 PID
```

**Option 2: Use a different port**
I can configure your app to use port 3001 instead.
Just say: "Use port 3001"

**Option 3: Automatic fix**
I can create a script that automatically finds an available port.
Just say: "Auto-select port"

Which option would you prefer?
```

---

**Issue: "npm install fails"**

**AI Response:**
```markdown
Let's fix this step by step:

**Step 1: Clear npm cache**
```bash
npm cache clean --force
```

**Step 2: Delete node_modules and package-lock.json**
```bash
rm -rf node_modules package-lock.json
```

**Step 3: Reinstall**
```bash
npm install
```

**If still failing:**
- Check your Node.js version: `node --version`
- Required version: 16.x or higher
- Update Node.js: https://nodejs.org/

**Alternative:**
Use `yarn` instead of `npm`:
```bash
npm install -g yarn
yarn install
```

Would you like me to try these fixes automatically?
```

---

**Issue: "Database connection failed"**

**AI Response:**
```markdown
Let's troubleshoot the database connection:

**Step 1: Check if database is running**
```bash
# For Docker
docker ps | grep postgres

# If not running, start it
docker-compose up -d
```

**Step 2: Verify connection string**
```bash
# Check your .env file
cat .env | grep DATABASE_URL

# Correct format:
# DATABASE_URL="postgresql://user:password@localhost:5432/dbname"
```

**Step 3: Test connection**
```bash
# For PostgreSQL
psql "$DATABASE_URL"

# If this works, your database is fine
# If not, check username/password
```

**Alternative Solutions:**

**Option 1: Use Supabase (Cloud Database)**
- No local setup needed
- Free tier available
- I can configure this for you
- Say: "Use Supabase instead"

**Option 2: Reset Database**
```bash
docker-compose down -v
docker-compose up -d
npm run migrate
```

Which option would you like to try?
```

---

### üìö Beginner-Friendly Explanations

**What is Docker?**
> **Simple explanation:** Docker is like a "box" that contains your application and everything it needs to run. This makes it easy to run your app on any computer without installation headaches.
> 
> **Do you need it?** Not always! I can set up your project without Docker using cloud services like Supabase.

**What is PostgreSQL?**
> **Simple explanation:** PostgreSQL is a database - think of it as an organized filing cabinet for your app's data (users, posts, invoices, etc.).
> 
> **Alternatives:** 
> - SQLite (simpler, no setup, good for small apps)
> - MongoDB (different style, flexible structure)
> - Supabase (cloud-hosted PostgreSQL, free tier)

**What is JWT?**
> **Simple explanation:** JWT is like a "ticket" that proves a user is logged in. When users log in, they get a ticket, and they show this ticket for every request.
> 
> **Why it's good:** Secure, scalable, works great for modern apps and mobile apps.

**What is an API?**
> **Simple explanation:** An API is how your frontend (what users see) talks to your backend (where data is stored). Like a waiter taking orders from customers to the kitchen.

**What is Deployment?**
> **Simple explanation:** Deployment means putting your app on the internet so others can use it. Like moving from your computer to a public website.
> 
> **Platforms:** Vercel (frontend), Railway (backend), Render, etc. (I'll recommend the best one for you)

**What is a Domain?**
> **Simple explanation:** A domain is your website's address, like `google.com` or `myapp.com`. Without a custom domain, you get a free subdomain like `myapp.vercel.app`.
> 
> **Do you need one?** Not required! Free subdomains work great. Custom domains cost $10-15/year.

**What is Environment Variable?**
> **Simple explanation:** Environment variables are secret settings for your app (like passwords, API keys). They're kept separate from your code for security.
> 
> **Example:** `DATABASE_URL`, `JWT_SECRET`, `STRIPE_KEY`

---

### üìã Post-Deployment Checklist

**AI Creates `docs/deployment-checklist.md`:**

```markdown
# Deployment Checklist

## ‚úÖ Pre-Deployment

- [ ] All tests passing locally (`npm run verify`)
- [ ] Environment variables documented in `.env.example`
- [ ] Database migrations ready
- [ ] Build succeeds locally (`npm run build`)
- [ ] No console errors or warnings
- [ ] Code pushed to GitHub
- [ ] README.md updated with project info

## ‚úÖ During Deployment

### Frontend (Vercel)
- [ ] Project deployed to Vercel
- [ ] Environment variables set in Vercel dashboard
- [ ] Build successful
- [ ] Custom domain connected (optional)

### Backend (Railway)
- [ ] Project deployed to Railway
- [ ] PostgreSQL database created
- [ ] Environment variables set
- [ ] Database migrations run
- [ ] Health check endpoint working

### Database (Supabase - if separate)
- [ ] Supabase project created
- [ ] Database schema deployed
- [ ] Connection string added to backend
- [ ] Authentication configured (if using)

## ‚úÖ Post-Deployment

- [ ] Test live URL (frontend)
- [ ] Test API endpoints (backend)
- [ ] Verify database connection
- [ ] Test user registration
- [ ] Test user login
- [ ] Test main features
- [ ] Check error logging
- [ ] Monitor performance
- [ ] Set up uptime monitoring (optional)

## üéâ Your App is Live!

**URLs:**
- Frontend: https://your-app.vercel.app
- Backend API: https://your-api.railway.app
- Database: Supabase dashboard

**Next Steps:**
1. ‚úÖ Share your app with users
2. üìä Monitor usage in platform dashboards
3. üåê Set up custom domain (optional)
4. üìà Configure analytics (optional)
5. üîî Set up error tracking (Sentry, optional)

**Monitoring:**
- Vercel: Check deployment logs and analytics
- Railway: Monitor resource usage and logs
- Supabase: Check database size and queries

**Costs:**
- Vercel: Free (100GB bandwidth/month)
- Railway: $5 free credit/month
- Supabase: Free (500MB database)

**When you'll need to upgrade:**
- Vercel: After 100GB bandwidth/month
- Railway: After $5 usage/month
- Supabase: After 500MB database or 50K users

**Estimated monthly cost for small app:** $0-5
**Estimated monthly cost for medium app:** $5-20
```

---

## Usage Examples

### Example 1: Simple REST API

```
User: I need a REST API for a task management system

AI: I'll help you build that! Let me gather some requirements.

1. What features do you need?
   - User authentication?
   - Task CRUD operations?
   - Task assignment to users?
   - Due dates and priorities?
   - Comments on tasks?

User: Yes to all

AI: Great! A few more questions:

2. Expected number of users?
User: Around 100-500 users

AI: 3. Tech stack preference?
   I recommend:
   - Backend: Node.js + Express + TypeScript
   - Database: PostgreSQL
   - Auth: JWT
   - ORM: Prisma
   
   Does this work for you?

User: Yes

AI: 4. Deployment preference?
   - Docker containerization? (Recommended)
   - Standalone?

User: Docker

AI: 5. Database server?
   - I can set up PostgreSQL in Docker
   - Or you can provide existing server details

User: Set it up in Docker

AI: Perfect! Generating project specification...

[Creates comprehensive spec]

Ready to proceed with phase planning?
```

---

### Example 2: Full-Stack Application

```
User: I want to build a SaaS platform for invoice management

AI: Excellent! Let's plan this properly.

[Goes through discovery questions]

AI: Based on your requirements, I recommend:

**Frontend:**
- React + TypeScript
- Tailwind CSS + shadcn/ui
- React Query for state management

**Backend:**
- Node.js + Express + TypeScript
- PostgreSQL with Prisma
- Redis for caching
- JWT authentication

**Infrastructure:**
- Docker Compose for local dev
- Nginx reverse proxy
- Multi-tenant architecture

**Security:**
- JWT with refresh tokens
- RBAC (Role-Based Access Control)
- API rate limiting
- Data encryption at rest

Does this align with your vision?

User: Perfect!

AI: [Generates detailed project spec]

I'll break this into 5 phases:
- P0: Foundation (auth, database, multi-tenancy)
- P1: Core features (invoice CRUD, PDF generation)
- P2: Advanced features (payments, notifications)
- P3: Reporting and analytics
- P4: Testing and deployment

Ready to bootstrap?
```

---

## Tech Stack Recommendations

### Backend Frameworks

**Node.js + Express**
- ‚úÖ Best for: REST APIs, real-time apps, microservices
- ‚úÖ Use when: JavaScript/TypeScript ecosystem preferred
- ‚úÖ Strengths: Large ecosystem, fast development, good for I/O-heavy apps

**Python + FastAPI**
- ‚úÖ Best for: Data-heavy apps, ML integration, rapid prototyping
- ‚úÖ Use when: Python ecosystem needed, data science integration
- ‚úÖ Strengths: Type safety, auto-generated docs, async support

**NestJS**
- ‚úÖ Best for: Enterprise applications, complex architectures
- ‚úÖ Use when: Need structure, dependency injection, scalability
- ‚úÖ Strengths: Angular-like architecture, built-in features, TypeScript-first

### Databases

**PostgreSQL**
- ‚úÖ Best for: Complex queries, relational data, ACID compliance
- ‚úÖ Use when: Data integrity critical, complex relationships

**MongoDB**
- ‚úÖ Best for: Flexible schemas, document storage, rapid iteration
- ‚úÖ Use when: Schema evolves frequently, nested data structures

**MySQL**
- ‚úÖ Best for: Traditional web apps, read-heavy workloads
- ‚úÖ Use when: Proven stability needed, simpler queries

**Redis**
- ‚úÖ Best for: Caching, sessions, real-time features
- ‚úÖ Use when: Performance critical, temporary data storage

### Authentication

**JWT (JSON Web Tokens)**
- ‚úÖ Best for: Stateless APIs, microservices, mobile apps
- ‚úÖ Use when: Scalability important, no server-side sessions

**OAuth 2.0**
- ‚úÖ Best for: Third-party integrations, social login
- ‚úÖ Use when: Need "Login with Google/GitHub/etc."

**Session-based**
- ‚úÖ Best for: Traditional web apps, server-side rendering
- ‚úÖ Use when: Simpler security model preferred

### Frontend Frameworks

**React**
- ‚úÖ Best for: SPAs, complex UIs, large ecosystems
- ‚úÖ Use when: Component reusability important

**Vue.js**
- ‚úÖ Best for: Progressive enhancement, simpler learning curve
- ‚úÖ Use when: Rapid development needed

**Next.js**
- ‚úÖ Best for: SEO-critical apps, server-side rendering
- ‚úÖ Use when: Performance and SEO both critical

---

## Phase Complexity Guidelines

### Simple Projects (2-3 Phases)
- Basic CRUD apps
- Simple REST APIs
- Portfolio websites
- Landing pages

**Example Phases:**
- P0: Setup + Core features
- P1: Additional features
- P2: Testing + Deployment

### Medium Projects (4-5 Phases)
- Multi-user applications
- E-commerce platforms
- Content management systems
- SaaS MVPs

**Example Phases:**
- P0: Foundation (auth, database)
- P1: Core features
- P2: Secondary features
- P3: Integrations
- P4: Testing + Deployment

### Complex Projects (6+ Phases)
- Enterprise applications
- Multi-tenant platforms
- Real-time collaboration tools
- Complex integrations

**Example Phases:**
- P0: Infrastructure + Architecture
- P1: Authentication + Authorization
- P2: Core domain features
- P3: Advanced features
- P4: Integrations + APIs
- P5: Admin panel + Analytics
- P6: Testing + Deployment

---

## Critical Rules for AI

### üõë NEVER Do This:
1. ‚ùå Ask 8-9 separate questions when one comprehensive question suffices
2. ‚ùå Proceed without AI analysis and recommendations
3. ‚ùå Move to next phase with failing tests
4. ‚ùå Ignore user's tech stack customization requests
5. ‚ùå Create files without explaining purpose
6. ‚ùå Skip testing phases
7. ‚ùå Present recommendations without justifications
8. ‚ùå Use hardcoded credentials
9. ‚ùå Skip error handling
10. ‚ùå Forget to document changes

### ‚úÖ ALWAYS Do This:
1. ‚úÖ Ask for brief project description (2-3 sentences)
2. ‚úÖ Analyze and provide complete architecture recommendations
3. ‚úÖ Justify all tech stack choices
4. ‚úÖ Use smart defaults from configuration matrix
5. ‚úÖ Allow easy customization of recommendations
6. ‚úÖ Wait for user approval at gates
7. ‚úÖ Test after every phase
8. ‚úÖ Document all decisions in `docs/`
9. ‚úÖ Add comments explaining changes
10. ‚úÖ Follow security best practices
11. ‚úÖ Create `.env.example` with all variables
12. ‚úÖ Generate comprehensive test suites
13. ‚úÖ Provide manual testing guide
14. ‚úÖ Auto-detect features from keywords
15. ‚úÖ Assign features to phases automatically

### üìù Documentation Requirements:
Every project MUST have:
- `docs/requirements.md` - Original requirements
- `docs/project-spec.md` - Technical specification
- `docs/folder-structure.md` - Directory layout
- `docs/database-schema.md` - Database design
- `docs/phases/p*.md` - Phase documentation
- `docs/manual-testing-guide.md` - Testing instructions
- `docs/production-checklist.md` - Deployment guide
- `README.md` - Project overview and setup
- `.env.example` - Environment variables template

---

## Testing Strategy

### Unit Tests
- Test individual functions/methods
- Mock external dependencies
- Aim for 80%+ coverage

### Integration Tests
- Test API endpoints
- Test database operations
- Test service interactions

### E2E Tests
- Test complete user flows
- Test critical paths
- Use tools like Playwright, Cypress

### Manual Testing
- Browser compatibility
- UI/UX validation
- Edge cases
- Error scenarios

---

## File Organization

```
project-root/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.md
‚îÇ   ‚îú‚îÄ‚îÄ project-spec.md
‚îÇ   ‚îú‚îÄ‚îÄ folder-structure.md
‚îÇ   ‚îú‚îÄ‚îÄ database-schema.md
‚îÇ   ‚îú‚îÄ‚îÄ manual-testing-guide.md
‚îÇ   ‚îú‚îÄ‚îÄ production-checklist.md
‚îÇ   ‚îî‚îÄ‚îÄ phases/
‚îÇ       ‚îú‚îÄ‚îÄ p0-foundation.md
‚îÇ       ‚îú‚îÄ‚îÄ p1-core-features.md
‚îÇ       ‚îú‚îÄ‚îÄ p2-secondary-features.md
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ server/
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îú‚îÄ‚îÄ prisma/
‚îÇ   ‚îî‚îÄ‚îÄ schema.prisma
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md
```

---

## Success Criteria

A project is considered complete when:

‚úÖ All phases implemented and tested
‚úÖ All acceptance criteria met
‚úÖ Test suite passing (80%+ coverage)
‚úÖ Manual testing guide created
‚úÖ Production checklist verified
‚úÖ Documentation complete
‚úÖ Environment variables documented
‚úÖ Error handling comprehensive (no blank pages on API failures)
‚úÖ Visual Excellence & Responsive Design (Tailwind/Modern UI)
‚úÖ Security best practices followed (no plain text passwords)
‚úÖ Code reviewed and optimized (proper TypeScript types used)

---

## Example Conversation Flow

```
User: Create a blog platform with user authentication

AI: I'll help you build a blog platform! Let me gather requirements.

**Project Discovery:**

1. What features do you need?
   - User registration/login?
   - Create/edit/delete posts?
   - Comments?
   - Categories/tags?
   - Rich text editor?
   - Image uploads?

User: Yes to all except image uploads for now

AI: 2. Expected scale?
   - Number of users?
   - Posts per day?

User: Start with 1000 users, maybe 50 posts/day

AI: 3. Tech Stack Recommendation:
   
   **Backend:**
   - Node.js + Express + TypeScript (fast development, great ecosystem)
   - PostgreSQL (relational data, complex queries)
   - Prisma ORM (type-safe, great DX)
   
   **Frontend:**
   - React + TypeScript (component reusability)
   - Tailwind CSS (rapid styling)
   - React Query (data fetching)
   - TipTap (rich text editor)
   
   **Authentication:**
   - JWT (stateless, scalable)
   
   Does this work for you or prefer different stack?

User: Looks good!

AI: 4. Deployment:
   - Docker containerization? (Recommended for consistency)
   - Or standalone?

User: Docker please

AI: 5. Database:
   - I'll set up PostgreSQL in Docker
   - Or provide existing server details?

User: Set it up in Docker

AI: Perfect! Generating comprehensive project specification...

[Creates detailed spec]

**Project Specification Summary:**

**Architecture:**
- Monolithic backend with REST API
- React SPA frontend
- PostgreSQL database
- JWT authentication
- Docker Compose for local dev

**Key Features:**
- User authentication (register, login, logout)
- Blog post CRUD with rich text
- Comments system
- Categories and tags
- User profiles
- Search functionality

**Security:**
- Password hashing (bcrypt)
- JWT with refresh tokens
- Input validation
- SQL injection prevention
- XSS protection

**Phase Breakdown:**
- P0: Foundation (4-6 hours)
  - Project setup, database, auth
- P1: Core Features (6-8 hours)
  - Post CRUD, rich text editor
- P2: Social Features (4-6 hours)
  - Comments, user profiles
- P3: Discovery (3-4 hours)
  - Categories, tags, search
- P4: Polish & Testing (4-6 hours)
  - Tests, documentation, deployment

Total Estimated: 21-30 hours

Approve specification?

User: Yes, let's do it!

AI: Excellent! Creating phase documents...

‚úÖ Created docs/requirements.md
‚úÖ Created docs/project-spec.md
‚úÖ Created docs/folder-structure.md
‚úÖ Created docs/database-schema.md
‚úÖ Created docs/phases/p0-foundation.md
‚úÖ Created docs/phases/p1-core-features.md
‚úÖ Created docs/phases/p2-social-features.md
‚úÖ Created docs/phases/p3-discovery.md
‚úÖ Created docs/phases/p4-polish-testing.md

Ready to bootstrap the project?

User: Yes!

AI: Bootstrapping project...

‚úÖ Created folder structure
‚úÖ Generated package.json
‚úÖ Generated tsconfig.json
‚úÖ Created docker-compose.yml
‚úÖ Created Dockerfile
‚úÖ Generated Prisma schema
‚úÖ Created .env.example
‚úÖ Created .gitignore
‚úÖ Generated server entry point
‚úÖ Created basic middleware
‚úÖ Added health check endpoint
‚úÖ Installing dependencies...
‚úÖ Dependencies installed
‚úÖ Testing bootstrap...
‚úÖ Server starts successfully
‚úÖ Database connection verified

Project bootstrapped successfully!

Starting Phase 0: Foundation...

**P0 Objectives:**
- Set up authentication system
- Create user model and migrations
- Implement register/login/logout
- Add JWT middleware
- Create user routes

Implementing...

[Creates all files with detailed comments]

‚úÖ Created src/models/user.model.ts
‚úÖ Created src/controllers/auth.controller.ts
‚úÖ Created src/routes/auth.routes.ts
‚úÖ Created src/middleware/auth.middleware.ts
‚úÖ Created src/utils/jwt.utils.ts
‚úÖ Created src/utils/password.utils.ts
‚úÖ Updated Prisma schema
‚úÖ Generated Prisma client
‚úÖ Ran migrations

Testing Phase 0...

‚úÖ POST /api/auth/register - Success
‚úÖ POST /api/auth/login - Success
‚úÖ GET /api/auth/me - Success (with token)
‚úÖ POST /api/auth/logout - Success

Gap Analysis:
‚úÖ All P0 acceptance criteria met
‚úÖ No gaps identified

**Phase 0 Complete!**

Summary:
- ‚úÖ User authentication working
- ‚úÖ JWT tokens generated
- ‚úÖ Protected routes functional
- ‚úÖ All tests passing

Continue to Phase 1: Core Features?

User: Yes!

[Continues through all phases...]

[After P4 completion]

AI: **All Phases Complete!**

Running final validation...

‚úÖ End-to-end user flow tested
‚úÖ All API endpoints working
‚úÖ Database operations verified
‚úÖ Authentication secure
‚úÖ Error handling comprehensive

Generating test suite...

‚úÖ Created tests/unit/auth.test.ts
‚úÖ Created tests/unit/posts.test.ts
‚úÖ Created tests/integration/api.test.ts
‚úÖ Created tests/e2e/user-flow.test.ts

Running tests...

‚úÖ 45 tests passing
‚úÖ 87% code coverage

Creating manual testing guide...

‚úÖ Created docs/manual-testing-guide.md

Creating production checklist...

‚úÖ Created docs/production-checklist.md

**Project Complete! üéâ**

Your blog platform is ready for deployment.

Next steps:
1. Review docs/manual-testing-guide.md
2. Test features in browser
3. Review docs/production-checklist.md
4. Deploy to your hosting platform

Would you like help with deployment?
```

---

## üîß TROUBLESHOOTING GUIDE

### Common Issues & Solutions

#### Issue 1: Database Connection Failed
**Symptoms:**
```
Error: connect ECONNREFUSED 127.0.0.1:5432
```

**Cause:** PostgreSQL not running or wrong connection string

**Solution:**
```bash
# Check if PostgreSQL is running
docker ps | grep postgres

# If using Docker Compose
docker-compose up -d postgres

# Verify connection
psql "$DATABASE_URL"

# Check .env file
cat .env | grep DATABASE_URL

# Correct format:
# DATABASE_URL="postgresql://user:password@localhost:5432/dbname"
```

---

#### Issue 2: Port Already in Use
**Symptoms:**
```
Error: listen EADDRINUSE: address already in use :::4000
```

**Cause:** Another process using the port

**Solution:**
```bash
# Find process using port
lsof -i :4000

# Kill the process
kill -9 <PID>

# Or use different port in .env
PORT=4001 npm run dev
```

---

#### Issue 3: Prisma Migration Failed
**Symptoms:**
```
Error: P3009: migrate found failed migration
```

**Cause:** Previous migration failed or database schema drift

**Solution:**
```bash
# Reset database (DEVELOPMENT ONLY!)
npx prisma migrate reset

# Or resolve migration
npx prisma migrate resolve --rolled-back <migration_name>

# Then retry
npx prisma migrate dev
```

---

#### Issue 4: TypeScript Compilation Errors
**Symptoms:**
```
error TS2307: Cannot find module '@/types/user'
```

**Cause:** Missing type definitions or incorrect paths

**Solution:**
```bash
# Regenerate Prisma client
npx prisma generate

# Check tsconfig.json paths
cat tsconfig.json | grep paths

# Install missing types
npm install -D @types/node @types/express

# Clear TypeScript cache
rm -rf node_modules/.cache
```

---

#### Issue 5: JWT Token Verification Failed
**Symptoms:**
```
Error: JsonWebTokenError: invalid signature
```

**Cause:** JWT_SECRET mismatch or token corruption

**Solution:**
```bash
# Verify JWT_SECRET is consistent
echo $JWT_SECRET

# Check .env file
cat .env | grep JWT_SECRET

# Regenerate secret if needed
node -e "console.log(require('crypto').randomBytes(64).toString('hex'))"

# Update .env with new secret
# Note: This will invalidate all existing tokens
```

---

#### Issue 6: CORS Errors in Browser
**Symptoms:**
```
Access to fetch at 'http://localhost:4000/api' from origin 
'http://localhost:3000' has been blocked by CORS policy
```

**Cause:** CORS not configured or wrong origin

**Solution:**
```typescript
// src/server/middleware/cors.ts
import cors from 'cors';

app.use(cors({
  origin: process.env.FRONTEND_URL || 'http://localhost:3000',
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'],
  allowedHeaders: ['Content-Type', 'Authorization']
}));
```

---

#### Issue 7: Environment Variables Not Loading
**Symptoms:**
```
undefined when accessing process.env.DATABASE_URL
```

**Cause:** .env file not loaded or wrong location

**Solution:**
```bash
# Install dotenv
npm install dotenv

# Load at app entry point
# src/server/index.ts
import 'dotenv/config';

# Verify .env location
ls -la .env

# Check if variables are loaded
node -e "require('dotenv').config(); console.log(process.env.DATABASE_URL)"
```

---

#### Issue 8: Docker Build Failed
**Symptoms:**
```
ERROR [stage-1 3/5] RUN npm install
```

**Cause:** Network issues, wrong Node version, or missing files

**Solution:**
```bash
# Clear Docker cache
docker builder prune -a

# Rebuild with no cache
docker-compose build --no-cache

# Check Dockerfile Node version
cat Dockerfile | grep FROM

# Ensure .dockerignore exists
cat .dockerignore
```

---

#### Issue 9: Tests Failing After Deployment
**Symptoms:**
```
Expected 200, got 500
```

**Cause:** Environment-specific configuration or missing migrations

**Solution:**
```bash
# Run migrations on target environment
npx prisma migrate deploy

# Check environment variables
env | grep -E "DATABASE_URL|JWT_SECRET|NODE_ENV"

# Verify database connection
npx prisma db pull

# Check logs
docker logs <container_name> --tail 100
```

---

#### Issue 11: Blank Page / Infinite Loop / React Crash
**Symptoms:**
- Page loads but is completely blank.
- Infinite redirection between `/login` and `/`.
- Console shows `React Error #31` or `Property 'env' does not exist on type 'ImportMeta'`.

**Cause:**
- Improper error handling (rendering error objects directly).
- Leaked backend types into TypeScript (e.g., `str` instead of `string`).
- Missing Vite environment type definitions.

**Solution:**
1. **Fix Types**: Ensure all interfaces use `string` (TypeScript) not `str` (Python).
2. **Vite Env**: Create `src/vite-env.d.ts` with correct definitions:
```typescript
/// <reference types="vite/client" />
interface ImportMetaEnv { readonly VITE_API_BASE_URL: string }
interface ImportMeta { readonly env: ImportMetaEnv }
```
3. **Safe Redirections**: Use `useEffect` for state-based navigation instead of inline `Navigate` in the render body.
4. **Error Boundaries**: Handle API errors in `catch` blocks by checking if they are strings or objects before setting them to state.
```typescript
const detail = err.response?.data?.detail;
setError(typeof detail === 'string' ? detail : 'An error occurred');
```

---

## üåç ENVIRONMENT SETUP GUIDE

### Development Environment

**Required Tools:**
```bash
# Node.js (v18+ recommended)
node --version

# npm or yarn
npm --version

# Docker (if using containerization)
docker --version
docker-compose --version

# PostgreSQL client (for database access)
psql --version

# Git
git --version
```

**Setup Steps:**
```bash
# 1. Clone repository
git clone <repo-url>
cd <project-name>

# 2. Install dependencies
npm install

# 3. Copy environment template
cp .env.example .env

# 4. Update .env with your values
nano .env

# 5. Start database (if using Docker)
docker-compose up -d postgres

# 6. Run migrations
npx prisma migrate dev

# 7. Seed database (if seed script exists)
npm run seed

# 8. Start development server
npm run dev
```

**Environment Variables Template:**
```bash
# .env.example

# Server Configuration
NODE_ENV=development
PORT=4000
FRONTEND_URL=http://localhost:3000

# Database
DATABASE_URL="postgresql://user:password@localhost:5432/dbname"

# Authentication
JWT_SECRET=your-super-secret-jwt-key-here
JWT_EXPIRES_IN=15m
REFRESH_TOKEN_EXPIRES_IN=7d

# Email (if applicable)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password

# Storage (if applicable)
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_REGION=us-east-1
AWS_S3_BUCKET=your-bucket-name

# External APIs (if applicable)
STRIPE_SECRET_KEY=sk_test_...
STRIPE_WEBHOOK_SECRET=whsec_...

# Monitoring (if applicable)
SENTRY_DSN=https://...@sentry.io/...
LOG_LEVEL=debug
```

---

### Staging Environment

**Configuration:**
```bash
# .env.staging

NODE_ENV=staging
PORT=4000
FRONTEND_URL=https://staging.yourapp.com

DATABASE_URL="postgresql://user:password@staging-db:5432/dbname"

JWT_SECRET=<strong-random-secret>
JWT_EXPIRES_IN=15m
REFRESH_TOKEN_EXPIRES_IN=7d

LOG_LEVEL=info
SENTRY_DSN=<your-sentry-dsn>
```

**Deployment:**
```bash
# Build application
npm run build

# Run migrations
npx prisma migrate deploy

# Start server
npm start

# Or with PM2
pm2 start npm --name "app-staging" -- start
```

---

### Production Environment

**Configuration:**
```bash
# .env.production

NODE_ENV=production
PORT=4000
FRONTEND_URL=https://yourapp.com

DATABASE_URL="postgresql://user:password@prod-db:5432/dbname"

JWT_SECRET=<very-strong-random-secret>
JWT_EXPIRES_IN=15m
REFRESH_TOKEN_EXPIRES_IN=7d

LOG_LEVEL=error
SENTRY_DSN=<your-sentry-dsn>

# Enable production optimizations
ENABLE_COMPRESSION=true
ENABLE_RATE_LIMITING=true
RATE_LIMIT_MAX=100
RATE_LIMIT_WINDOW=15
```

**Security Checklist:**
- [ ] All secrets are environment variables (never hardcoded)
- [ ] JWT_SECRET is cryptographically random (64+ characters)
- [ ] Database credentials are strong and unique
- [ ] HTTPS enabled (TLS 1.3)
- [ ] CORS configured with specific origins
- [ ] Rate limiting enabled
- [ ] Input validation on all endpoints
- [ ] SQL injection prevention (parameterized queries)
- [ ] XSS protection (Content Security Policy)
- [ ] Helmet.js middleware enabled
- [ ] Dependencies updated (npm audit)
- [ ] Error messages don't leak sensitive info
- [ ] Logging excludes sensitive data

---

## üìä MONITORING & OBSERVABILITY

### Application Metrics

**Health Check Endpoint:**
```typescript
// src/server/routes/health.routes.ts
import { Router } from 'express';
import { PrismaClient } from '@prisma/client';

const router = Router();
const prisma = new PrismaClient();

router.get('/health', async (req, res) => {
  try {
    // Check database connection
    await prisma.$queryRaw`SELECT 1`;
    
    res.json({
      status: 'ok',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      environment: process.env.NODE_ENV,
      version: process.env.npm_package_version,
      database: 'connected',
      memory: {
        used: Math.round(process.memoryUsage().heapUsed / 1024 / 1024),
        total: Math.round(process.memoryUsage().heapTotal / 1024 / 1024),
      },
    });
  } catch (error) {
    res.status(503).json({
      status: 'error',
      database: 'disconnected',
      error: error.message,
    });
  }
});

export default router;
```

**Performance Monitoring:**
```typescript
// src/server/middleware/metrics.ts
import { Request, Response, NextFunction } from 'express';

export const metricsMiddleware = (req: Request, res: Response, next: NextFunction) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - start;
    
    console.log({
      method: req.method,
      path: req.path,
      status: res.statusCode,
      duration: `${duration}ms`,
      timestamp: new Date().toISOString(),
    });
    
    // Send to monitoring service (e.g., Prometheus, DataDog)
    // metrics.recordHttpRequest(req.method, req.path, res.statusCode, duration);
  });
  
  next();
};
```

---

### Logging Best Practices

**Structured Logging:**
```typescript
// src/server/utils/logger.ts
import winston from 'winston';

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'api-server' },
  transports: [
    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/combined.log' }),
  ],
});

if (process.env.NODE_ENV !== 'production') {
  logger.add(new winston.transports.Console({
    format: winston.format.combine(
      winston.format.colorize(),
      winston.format.simple()
    ),
  }));
}

export default logger;
```

**Usage:**
```typescript
import logger from './utils/logger';

// Info logs
logger.info('User logged in', { userId: user.id, email: user.email });

// Error logs
logger.error('Database query failed', { error: error.message, query: sql });

// Warning logs
logger.warn('Rate limit exceeded', { ip: req.ip, endpoint: req.path });
```

---

### Database Monitoring

**Query Performance:**
```sql
-- Slow query log (PostgreSQL)
ALTER SYSTEM SET log_min_duration_statement = 1000; -- Log queries > 1s
SELECT pg_reload_conf();

-- View slow queries
SELECT 
  query,
  calls,
  total_time,
  mean_time,
  max_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;
```

**Connection Pool Monitoring:**
```typescript
// src/server/config/database.ts
import { PrismaClient } from '@prisma/client';

const prisma = new PrismaClient({
  log: [
    { level: 'query', emit: 'event' },
    { level: 'error', emit: 'stdout' },
    { level: 'warn', emit: 'stdout' },
  ],
});

prisma.$on('query', (e) => {
  if (e.duration > 1000) {
    logger.warn('Slow query detected', {
      query: e.query,
      duration: `${e.duration}ms`,
    });
  }
});

export default prisma;
```

---

## üöÄ DEPLOYMENT STRATEGIES

### Docker Deployment

**Multi-stage Dockerfile:**
```dockerfile
# Stage 1: Build
FROM node:18-alpine AS builder

WORKDIR /app

COPY package*.json ./
COPY prisma ./prisma/

RUN npm ci
RUN npx prisma generate

COPY . .
RUN npm run build

# Stage 2: Production
FROM node:18-alpine

WORKDIR /app

COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/prisma ./prisma
COPY package*.json ./

ENV NODE_ENV=production

EXPOSE 4000

CMD ["npm", "start"]
```

**Docker Compose (Production):**
```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "4000:4000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:pass@postgres:5432/db
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    restart: unless-stopped

volumes:
  postgres_data:
```

---

### Cloud Deployment (AWS Example)

**Elastic Beanstalk:**
```bash
# Install EB CLI
pip install awsebcli

# Initialize
eb init -p node.js-18 my-app

# Create environment
eb create production-env

# Deploy
eb deploy

# View logs
eb logs
```

**ECS (Fargate):**
```bash
# Build and push Docker image
docker build -t my-app .
docker tag my-app:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/my-app:latest
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/my-app:latest

# Create ECS task definition
aws ecs register-task-definition --cli-input-json file://task-definition.json

# Update service
aws ecs update-service --cluster my-cluster --service my-app --task-definition my-app:1
```

---

### CI/CD Pipeline (GitHub Actions)

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 18
      - run: npm ci
      - run: npm test
      - run: npm run build
      
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      
      - name: Build and push Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: my-app
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
      
      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster my-cluster \
            --service my-app \
            --force-new-deployment
```

---

## üìà PERFORMANCE OPTIMIZATION

### Database Optimization

**Indexing Strategy:**
```sql
-- Add indexes for frequently queried columns
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_posts_author_id ON posts(author_id);
CREATE INDEX idx_posts_created_at ON posts(created_at DESC);

-- Composite indexes for multi-column queries
CREATE INDEX idx_posts_status_created ON posts(status, created_at DESC);

-- Partial indexes for filtered queries
CREATE INDEX idx_active_users ON users(email) WHERE status = 'active';
```

**Query Optimization:**
```typescript
// Bad: N+1 query problem
const posts = await prisma.post.findMany();
for (const post of posts) {
  const author = await prisma.user.findUnique({ where: { id: post.authorId } });
}

// Good: Use include/select
const posts = await prisma.post.findMany({
  include: {
    author: {
      select: { id: true, name: true, email: true }
    }
  }
});
```

---

### Caching Strategy

**Redis Integration:**
```typescript
// src/server/utils/cache.ts
import Redis from 'ioredis';

const redis = new Redis(process.env.REDIS_URL);

export async function getCached<T>(key: string, fallback: () => Promise<T>, ttl = 3600): Promise<T> {
  const cached = await redis.get(key);
  
  if (cached) {
    return JSON.parse(cached);
  }
  
  const data = await fallback();
  await redis.setex(key, ttl, JSON.stringify(data));
  
  return data;
}

// Usage
const user = await getCached(
  `user:${userId}`,
  () => prisma.user.findUnique({ where: { id: userId } }),
  3600 // 1 hour
);
```

---

### API Response Compression

```typescript
// src/server/middleware/compression.ts
import compression from 'compression';

app.use(compression({
  filter: (req, res) => {
    if (req.headers['x-no-compression']) {
      return false;
    }
    return compression.filter(req, res);
  },
  level: 6 // Balance between speed and compression ratio
}));
```

---

## üìö QUICK REFERENCE

### Command Cheat Sheet

**Development:**
```bash
# Start development server
npm run dev

# Run tests
npm test

# Run tests in watch mode
npm test -- --watch

# Check types
npm run type-check

# Lint code
npm run lint

# Format code
npm run format
```

**Database:**
```bash
# Create migration
npx prisma migrate dev --name migration_name

# Apply migrations (production)
npx prisma migrate deploy

# Reset database (dev only)
npx prisma migrate reset

# Open Prisma Studio
npx prisma studio

# Generate Prisma client
npx prisma generate
```

**Docker:**
```bash
# Build and start all services
docker-compose up -d

# View logs
docker-compose logs -f app

# Restart service
docker-compose restart app

# Stop all services
docker-compose down

# Rebuild specific service
docker-compose build app
```

---

## üéØ SUCCESS METRICS

A DOC2PROD project is considered successful when:

### Technical Metrics
- ‚úÖ All phases completed and tested
- ‚úÖ Test coverage ‚â• 80%
- ‚úÖ All acceptance criteria met
- ‚úÖ Zero critical security vulnerabilities
- ‚úÖ API response time < 200ms (p95)
- ‚úÖ Database queries optimized (< 100ms)
- ‚úÖ Build time < 5 minutes
- ‚úÖ Docker image size < 500MB

### Documentation Metrics
- ‚úÖ README.md complete with setup instructions
- ‚úÖ API documentation generated
- ‚úÖ All environment variables documented
- ‚úÖ Manual testing guide created
- ‚úÖ Production deployment guide ready
- ‚úÖ Troubleshooting guide available

### Quality Metrics
- ‚úÖ Code follows consistent style guide
- ‚úÖ No hardcoded secrets or credentials
- ‚úÖ Error handling comprehensive
- ‚úÖ Logging implemented throughout
- ‚úÖ Input validation on all endpoints
- ‚úÖ CORS properly configured
- ‚úÖ Rate limiting implemented

### Deployment Metrics
- ‚úÖ Application runs in Docker
- ‚úÖ Health check endpoint responds
- ‚úÖ Database migrations automated
- ‚úÖ Environment-specific configs ready
- ‚úÖ CI/CD pipeline configured
- ‚úÖ Monitoring and alerting setup

---

## üîÑ CONTINUOUS IMPROVEMENT

### Post-Deployment Tasks

**Week 1:**
- [ ] Monitor error rates and response times
- [ ] Review user feedback
- [ ] Check database performance
- [ ] Verify backup procedures
- [ ] Test disaster recovery

**Month 1:**
- [ ] Analyze usage patterns
- [ ] Optimize slow queries
- [ ] Review and update documentation
- [ ] Security audit
- [ ] Dependency updates

**Quarter 1:**
- [ ] Performance benchmarking
- [ ] Scalability testing
- [ ] Feature usage analysis
- [ ] Cost optimization review
- [ ] Team retrospective

---

## Integration with Other Skills

DOC2PROD can work alongside:

- **app-init**: For initial project setup
- **schema-generation**: For complex database designs
- **secure-llm-proxy**: For AI-powered features
- **rag-integration**: For knowledge-based features
- **qa-automation**: For advanced testing
- **production-review**: For final security audit

---

## Skill Activation

This skill activates when user mentions:
- "Create a new project"
- "Build an application"
- "Start from scratch"
- "Generate full project"
- "Documentation to production"
- "I need to build [description]"
- "doc2prod"

---

## üìñ ADDITIONAL RESOURCES

### Learning Resources
- **Node.js Best Practices**: https://github.com/goldbergyoni/nodebestpractices
- **TypeScript Handbook**: https://www.typescriptlang.org/docs/handbook/
- **Prisma Documentation**: https://www.prisma.io/docs
- **Express.js Guide**: https://expressjs.com/en/guide/
- **Docker Best Practices**: https://docs.docker.com/develop/dev-best-practices/

### Tools & Libraries
- **Testing**: Jest, Supertest, Playwright
- **Validation**: Zod, Joi, Yup
- **Logging**: Winston, Pino, Morgan
- **Monitoring**: Sentry, DataDog, New Relic
- **Documentation**: Swagger, TypeDoc, Docusaurus

---

## Version

**Version:** 2.0.0
**Last Updated:** 2026-01-19
**Status:** Active ‚úÖ
**Changelog:**
- v2.0.0: Complete rewrite with comprehensive detail matching asgais2prod standards
  - Added YAML frontmatter
  - Added Moot Point philosophy
  - Added detailed execution pipeline
  - Added comprehensive troubleshooting guide
  - Added environment setup guides
  - Added monitoring and observability section
  - Added deployment strategies
  - Added performance optimization guides
  - Enhanced with 800+ lines of production-ready examples
- v1.0.0: Initial release

---

## Support & Contribution

**Created by:** ASG AI S2PROD Team at [AIShift](https://aishift.dev/)

**For Support:**
- üìß Email: info@aishift.dev
- üåê Website: https://aishift.dev
- üìö Documentation: https://docs.aishift.dev

**Contributing:**
This skill is part of the ASG AI S2PROD framework. To contribute improvements:
1. Test changes thoroughly
2. Document new features
3. Follow existing patterns
4. Submit detailed change descriptions

---

**Powered by ASG AI S2PROD** - Transform Ideas into Production Reality

---

## üéì SKILL PHILOSOPHY

DOC2PROD embodies the core principles of modern software development:

1. **Automation First**: Automate repetitive tasks, let humans focus on creativity
2. **Quality by Design**: Build quality in from the start, not as an afterthought
3. **Documentation as Code**: Documentation should be as important as code
4. **Security by Default**: Security should be built-in, not bolted-on
5. **Continuous Validation**: Test early, test often, test everything
6. **User-Centric**: Always keep the end user's needs in focus
7. **Production Ready**: Every deliverable should be deployment-ready

---

**Remember:** The goal is not just to write code, but to deliver production-ready applications that solve real problems for real users.
